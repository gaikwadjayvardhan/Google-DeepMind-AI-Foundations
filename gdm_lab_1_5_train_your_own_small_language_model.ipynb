{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gaikwadjayvardhan/Google-DeepMind-AI-Foundations/blob/main/gdm_lab_1_5_train_your_own_small_language_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McySAWvt09wn"
      },
      "source": [
        "> <p><small><small>This Notebook is made available subject to the licence and terms set out in the <a href = \"http://www.github.com/google-deepmind/ai-foundations\">AI Research Foundations Github README file</a>."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://storage.googleapis.com/dm-educational/assets/ai_foundations/GDM-Labs-banner-image-C1-white-bg.png\">"
      ],
      "metadata": {
        "id": "bg_nGpxOxaPv"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bW1AyB_f7eo"
      },
      "source": [
        "# Lab: Train Your Own Small Language Model\n",
        "\n",
        "<a href='https://colab.research.google.com/github/google-deepmind/ai-foundations/blob/master/course_1/gdm_lab_1_5_train_your_own_small_language_model.ipynb' target='_parent'><img src='https://colab.research.google.com/assets/colab-badge.svg' alt='Open In Colab'/></a>     \n",
        "\n",
        "40 minutes\n",
        "\n",
        "Train a transformer language model on the Africa Galore dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview\n",
        "\n",
        "In this lab, you will make use of the data pre-processing steps that you have implememented in the previous lab and prepare the data to be used for training a transformer model. You will then train your own small language model on the Africa Galore dataset and explore its predictions. The model you will be training is referred to as a small language model because it has comparably fewer parameters (around 3.5 million instead of the approximately 1 billion of Gemma-1B) and will be trained on the small Africa Galore dataset.\n",
        "\n"
      ],
      "metadata": {
        "id": "md4FSU7h9dQR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What you will learn:\n",
        "\n",
        "By the end of this lab, you will know:\n",
        "\n",
        "* How to prepare a text dataset to be used for training a transformer model with Keras.\n",
        "* How to train and evaluate a small language model (SLM).\n"
      ],
      "metadata": {
        "id": "g8u6btAn9jc4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tasks\n",
        "\n",
        "You will use an implementation of the transformer model written using [Keras](https://keras.io/). Keras is an open source deep learning framework that allows you to define neural network architectures and train models using these architectures. You will learn more about how to define models yourself in later courses. For now, you will use existing code to define the model and perform its training.\n",
        "\n",
        "\n",
        "**In this lab, you will**:\n",
        "* Load the dataset, tokenize it, and convert it to token IDs.\n",
        "* Pad the dataset such that all sequences have the same length.\n",
        "* Shuffle the examples in the dataset and group them into batches.\n",
        "* Transform the data into model inputs and model targets.\n",
        "* Train the transformer model.\n",
        "\n",
        "Note that this is quite a long lab since there are many steps that you have to go through for training a transformer language model and the training itself takes some time. If you are able to, we *highly recommend* running the code in this lab on a Colab instance with a GPU. See the section \"How to use Google Colaboratory (Colab)\" below for instructions on how to do this.\n",
        "\n"
      ],
      "metadata": {
        "id": "qIhcVxx0foVo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How to use Google Colaboratory (Colab)"
      ],
      "metadata": {
        "id": "NDWsJUGcf4Ru"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Google Colaboratory (also known as Google Colab) is a platform that allows you to run Python code in your browser. The code is written in **cells** that are excuted on a remote server.\n",
        "\n",
        "To run a cell, hover over a cell, and click on the `run` button to its left. The run button is the circle with the triangle (â–¶). Alternatively, you can also click on a cell and use the keyboard combination Ctrl+Return (or âŒ˜+Return if you are using a Mac).\n",
        "\n",
        "To try this out, run the following cell. This should print today's day of the week below it."
      ],
      "metadata": {
        "id": "wlNG_jg-39Zj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "print(f\"Today is {datetime.today():%A}.\")"
      ],
      "metadata": {
        "id": "UyTT6C0JhGBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that the *order in which you run the cells matters*. When you are working through a lab, make sure to always run *all* cells in order. Otherwise, the code might not work. If you take a break while working on a lab, Colab may disconnect you and in that case, you have to execute all cells again before  continuing your work. To make this easier, you can select the cell you are currently working on and then choose __Runtime â†’ Run before__  from the menu above (or use the keyboard combination Ctrl/âŒ˜ + F8). This will re-execute all cells before the current one."
      ],
      "metadata": {
        "id": "pbtgZxrpjm6j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using Colab with a GPU\n",
        "\n",
        "A **GPU** is a special type of hardware that can significantly speed up some types of computations of machine learning models. Several of the activities in this lab will also run a lot faster if you run them on a GPU.\n",
        "\n",
        "Follow these steps to run the activities in this lab on a GPU:\n",
        "\n",
        "1.  In the top menu bar, click on **Runtime**.\n",
        "2.  Select **Change runtime type** from the dropdown menu.\n",
        "3.  In the pop-up window under **Hardware Accelerator**, select **GPU** (usually listed as `T4 GPU`).\n",
        "5.  Click **Save**.\n",
        "\n",
        "Your Colab session will now restart with GPU access.\n",
        "\n",
        "Note that access to GPUs is limited and at times, you may not be able to run this lab on a GPU. All activities will still work but they will run slower and you will have to wait longer for some of the cells to finish running.\n"
      ],
      "metadata": {
        "id": "qLvkcx5pUItk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports\n",
        "\n"
      ],
      "metadata": {
        "id": "WQQlDe0hL8AY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this lab, you will make use of the Keras package for defining and training the transformer model, the [Pandas](http://pandas.pydata.org) package for reading the dataset, and the [TensorFlow](https://tensorflow.org) package for shuffling the data and grouping it into batches. Run the following cell to import these packages."
      ],
      "metadata": {
        "id": "UPJE5CKOA2bJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sYqG7iVwXEX0"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install \"git+https://github.com/google-deepmind/ai-foundations.git@main\"\n",
        "\n",
        "# Packages used.\n",
        "import os # Used for setting Keras configuration variables.\n",
        "os.environ[\"KERAS_BACKEND\"] = \"jax\" # Set a parameter for Keras.\n",
        "import re # Used for splitting text on whitespace.\n",
        "\n",
        "import keras # Used for defining an training the model.\n",
        "import pandas as pd # Used for loading the dataset.\n",
        "import tensorflow as tf # Used for shuffling the dataset.\n",
        "\n",
        "# Used for displaying nicer error messages.\n",
        "from IPython.display import display, HTML\n",
        "from ai_foundations import training # For training your model.\n",
        "from ai_foundations import generation # For prompting your model.\n",
        "from ai_foundations import visualizations # For visualizing probabilities.\n",
        "from ai_foundations.feedback.course_1 import slm # For providing feedback.\n",
        "\n",
        "# The following line provides configuration for Keras.\n",
        "keras.utils.set_random_seed(812)  # For Keras layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1XAXcZ9S-4w"
      },
      "source": [
        "## Loading and tokenizing the dataset\n",
        "\n",
        "Load the dataset. As in previous labs, you will use the [Africa Galore](https://storage.googleapis.com/dm-educational/assets/ai_foundations/africa_galore.json) dataset to train the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5mB31TuPSoWb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92f46948-f3c3-4374-9a97-3bca221da008"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded dataset with 232 paragraphs.\n"
          ]
        }
      ],
      "source": [
        "africa_galore = pd.read_json(\n",
        "    \"https://storage.googleapis.com/dm-educational/assets/ai_foundations/africa_galore.json\"\n",
        ")\n",
        "dataset = africa_galore[\"description\"].values\n",
        "print(\"Loaded dataset with\", dataset.shape[0], \"paragraphs.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsgXxQ8KGNfT"
      },
      "source": [
        "### Tokenization\n",
        "\n",
        "The following cell contains the  `SimpleWordTokenizer` class that you have encountered in the previous lab. You will use this class again to tokenize the dataset, prepare the vocabulary, and provide methods for translating tokens into token IDs and vice versa. Note that this version also adds special `<PAD>` and `<UNK>` tokens to the vocabulary. You will learn more about the purpose of these special tokens as part of this lab.\n",
        "\n",
        "Run the following cell to define the `SimpleWordTokenizer` and tokenize the Africa Galore dataset, and translate its tokens to IDs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LMK-adL0su6i"
      },
      "outputs": [],
      "source": [
        "class SimpleWordTokenizer:\n",
        "    \"\"\"A simple word tokenizer.\n",
        "\n",
        "    The tokenizer splits the text sequence based on whitespace, using the\n",
        "    `encode` method to convert the text into a sequence of indices and the\n",
        "    `decode` method to convert indices back into text.\n",
        "\n",
        "    The simple word tokenizer that can be initialized with a corpus or using a\n",
        "    provided vocabulary list\n",
        "\n",
        "    Typical usage example:\n",
        "\n",
        "        corpus = \"Hello there!\"\n",
        "        tokenizer = SimpleWordTokenizer(text)\n",
        "        print(tokenizer.encode('Hello'))\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Define constants.\n",
        "    UNKNOWN_TOKEN = \"<UNK>\"\n",
        "    PAD_TOKEN = \"<PAD>\"\n",
        "\n",
        "    def __init__(self, corpus: list[str], vocabulary: list[str] | None = None):\n",
        "        \"\"\"Initializes the tokenizer with texts in corpus or with a vocabulary.\n",
        "\n",
        "        Args:\n",
        "          corpus: Input text dataset.\n",
        "          vocabulary: A pre-defined vocabulary. If None,\n",
        "              the vocabulary is automatically inferred from the texts.\n",
        "        \"\"\"\n",
        "\n",
        "        if vocabulary is None:\n",
        "            # Build the vocabulary from scratch.\n",
        "            if isinstance(corpus, str):\n",
        "                corpus = [corpus]\n",
        "\n",
        "            # Convert text sequence to tokens.\n",
        "            tokens = []\n",
        "            for text in corpus:\n",
        "                for token in self.space_tokenize(text):\n",
        "                    tokens.append(token)\n",
        "\n",
        "            # Create a vocabulary comprising of unique tokens.\n",
        "            vocabulary = self.build_vocabulary(tokens)\n",
        "\n",
        "            # Add special unknown and pad tokens to the vocabulary list.\n",
        "            self.vocabulary = (\n",
        "                [self.PAD_TOKEN] + vocabulary + [self.UNKNOWN_TOKEN]\n",
        "            )\n",
        "\n",
        "        else:\n",
        "            self.vocabulary = vocabulary\n",
        "\n",
        "        # Size of vocabulary.\n",
        "        self.vocabulary_size = len(self.vocabulary)\n",
        "\n",
        "        # Create token-to-index and index-to-token mappings.\n",
        "        self.token_to_index = {}\n",
        "        self.index_to_token = {}\n",
        "        # Loop through all tokens in the vocabulary. enumerate automatically\n",
        "        # assigns a unique index to each token.\n",
        "        for index, token in enumerate(self.vocabulary):\n",
        "            self.token_to_index[token] = index\n",
        "            self.index_to_token[index] = token\n",
        "\n",
        "        # Map the special tokens to their IDs.\n",
        "        self.pad_token_id = self.token_to_index[self.PAD_TOKEN]\n",
        "        self.unknown_token_id = self.token_to_index[self.UNKNOWN_TOKEN]\n",
        "\n",
        "    def space_tokenize(self, text: str) -> list[str]:\n",
        "        \"\"\"Splits a given text on whitespace into tokens.\n",
        "\n",
        "        Args:\n",
        "            text: Text to split on whitespace.\n",
        "\n",
        "        Returns:\n",
        "            List of tokens after splitting `text`.\n",
        "        \"\"\"\n",
        "\n",
        "        # Use re.split such that multiple spaces are treated as a single\n",
        "        # separator.\n",
        "        return re.split(\" +\", text)\n",
        "\n",
        "    def join_text(self, text_list: list[str]) -> str:\n",
        "        \"\"\"Combines a list of tokens into a single string.\n",
        "\n",
        "        The combined tokens, as a single string, are separated by spaces in the\n",
        "        string.\n",
        "\n",
        "        Args:\n",
        "            text_list: List of tokens to be joined.\n",
        "\n",
        "        Returns:\n",
        "            String with all tokens joined with a whitespace.\n",
        "\n",
        "        \"\"\"\n",
        "        return \" \".join(text_list)\n",
        "\n",
        "    def build_vocabulary(self, tokens: list[str]) -> list[str]:\n",
        "        \"\"\"Create a vocabulary list from the list of tokens.\n",
        "\n",
        "        Args:\n",
        "            tokens: The list of tokens in the dataset.\n",
        "\n",
        "        Returns:\n",
        "            List of unique tokens (vocabulary) in the dataset.\n",
        "        \"\"\"\n",
        "        return sorted(list(set(tokens)))\n",
        "\n",
        "    def encode(self, text: str) -> list[int]:\n",
        "        \"\"\"Encodes a text sequence into a list of indices.\n",
        "\n",
        "        Args:\n",
        "            text: The input text to be encoded.\n",
        "\n",
        "        Returns:\n",
        "            A list of indices corresponding to the tokens in the input text.\n",
        "        \"\"\"\n",
        "\n",
        "        # Convert tokens into indices.\n",
        "        indices = []\n",
        "        unk_index = self.token_to_index[self.UNKNOWN_TOKEN]\n",
        "        for token in self.space_tokenize(text):\n",
        "            token_index = self.token_to_index.get(token, unk_index)\n",
        "            indices.append(token_index)\n",
        "\n",
        "        return indices\n",
        "\n",
        "    def decode(self, indices: int | list[int]) -> str:\n",
        "        \"\"\"Decodes a list (or single index) of integers back into tokens.\n",
        "\n",
        "        Args:\n",
        "            indices: A single index or a list of indices to be\n",
        "                decoded into tokens.\n",
        "\n",
        "        Returns:\n",
        "            A string of decoded tokens corresponding to the input indices.\n",
        "        \"\"\"\n",
        "\n",
        "        # If a single integer is passed, convert it into a list.\n",
        "        if isinstance(indices, int):\n",
        "            indices = [indices]\n",
        "\n",
        "        # Map indices to tokens.\n",
        "        tokens = []\n",
        "        for index in indices:\n",
        "            token = self.index_to_token.get(index, self.unknown_token_id)\n",
        "            tokens.append(token)\n",
        "\n",
        "        # Join the decoded tokens into a single string.\n",
        "        return self.join_text(tokens)\n",
        "\n",
        "\n",
        "# Initialize the tokenizer. This will build the tokenizer's vocabulary with\n",
        "# all the tokens that appear in the dataset.\n",
        "tokenizer = SimpleWordTokenizer(dataset)\n",
        "\n",
        "# Translate all tokens to their corresponding IDs.\n",
        "encoded_tokens = []\n",
        "for text in dataset:\n",
        "    # Split text into tokens and translate the tokens to token IDs.\n",
        "    token_ids = tokenizer.encode(text)\n",
        "    encoded_tokens.append(token_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shQvu8OqIuGY"
      },
      "source": [
        "To verify that this process was successful, inspect the first ten token IDs in the first example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "XWRFQkRFI1df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a480f51b-8407-4f22-abe0-118636ab0e3e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[814, 511, 985, 5092, 4802, 5183, 2800, 1363, 4792, 2134]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "encoded_tokens[0][:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38uEXAhL6Rmc"
      },
      "source": [
        "## Padding the dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2HzW94G7PVG"
      },
      "source": [
        "------\n",
        "> **â„¹ï¸ Info: Padding and truncating**\n",
        ">\n",
        ">The input to transformer models (or deep learning models more generally) is a **matrix** where each row corresponds to the data for one example in the dataset. In the case of the language model you will be training, each paragraph from the Africa Galore dataset constitutes an example. The input should therefore be a matrix that has the IDs of every token in a paragraph. In this matrix, the first entry of a row should be the ID of the first token, the second entry should be the ID of the second token, the third entry should be the ID of the third token, and so on.\n",
        ">\n",
        ">However, the paragraphs in a dataset rarely all have exactly the same length. This causes a problem when you try to combine the data of multiple paragraphs into a matrix, since every row in a matrix must have the same number of entries.\n",
        ">\n",
        ">There are two common solutions to this problem:\n",
        ">1. You can use a special `<PAD>` token to ensure that all sequences have the same length. This way, you can pad shorter paragraphs to match the length of the longest paragraph. This is done by adding `<PAD>` tokens at the beginning or the end of the paragraph. This results in all paragraphs having exactly the same length so that they can be combined in one matrix.\n",
        ">2. Another option is to truncate paragraphs. That is, removing the tokens at the beginning or the end of a paragraph so that they have the length of the shortest paragraph. This, however, may remove a lot of information from the dataset. For example, if the shortest paragraph has only five tokens, then you would shorten every paragraph to five tokens and remove almost all tokens.\n",
        ">\n",
        "> It is also possible to combine both of these methods so that you choose a target length. That way, very long paragraphs that exceed this length are truncated and short paragraphs whose length is below the target length are padded.\n",
        ">\n",
        ">The combination of truncating and padding is what is usually done in practice. You will implement this in the next activity to prepare the data for training the model.\n",
        "------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWA-cd-K_ql3"
      },
      "source": [
        "### Coding Activity 1: Compute length statistics\n",
        "\n",
        "To get a sense of what the dataset looks like and how much padding is needed, compute some statstics of the length of the dataset.\n",
        "\n",
        "First, look at the length of the first paragraph:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "e_RgRB6gvL6B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9e792c5-4f25-4785-d0b6-66437f9c87c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of first paragraph: 118\n"
          ]
        }
      ],
      "source": [
        "print(f\"Length of first paragraph: {len(encoded_tokens[0]):,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCEiSccJ9Y-3"
      },
      "source": [
        "------\n",
        "> ðŸ’» **Your task:**\n",
        ">\n",
        "> Complete the following cell to compute the length of the shortest paragraph and the length of the longest paragraph.\n",
        ">\n",
        "> There are multiple ways you go about this. For example, you could write a loop that goes through all paragraphs in `encoded_tokens`. You could update variables for the shortest and longest paragraph length whenever you encounter a shorter or longer paragraph than previously seen.\n",
        ">\n",
        "> Alternatively, you can use the `min` and `max` functions in combination with the `len` function in Python. For example, if you have a list of lists `list_of_lists`, then\n",
        ">`min(list_of_lists, key=len)` returns the list in `list_of_lists` with the shortest list (or one of them if there are multiple that have the same length).\n",
        "------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "LY2hke_k_LT0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d04aea3-04b6-4a11-81f9-334f0ec57ba3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of the shortest paragraph is: 26\n",
            "Length of the longest paragraph is: 318\n"
          ]
        }
      ],
      "source": [
        "shortest_paragraph_length = len(min(encoded_tokens, key=len))\n",
        "longest_paragraph_length = len(max(encoded_tokens, key=len))\n",
        "\n",
        "print(f\"Length of the shortest paragraph is:\", shortest_paragraph_length)\n",
        "print(f\"Length of the longest paragraph is:\", longest_paragraph_length)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Run this cell to test your code\n",
        "\n",
        "slm.test_max_min_seqlen(\n",
        "    shortest_paragraph_length, longest_paragraph_length, encoded_tokens\n",
        ")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "qVf0wHPuPV-3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e064b50-4443-49b3-9f29-b56149f6801a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Nice! Your answer looks correct.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c5Vsplt_L8b"
      },
      "source": [
        "You can now use this information to set the target length (`max_length`) for padding and truncating the paragraphs in your dataset. The cell below does this behind the scenes using the [`keras.preprocessing.sequence.pad_sequences`](https://github.com/keras-team/keras/blob/v3.10.0/keras/src/utils/sequence_utils.py#L12) function from the Keras package.\n",
        "\n",
        "Change the value below to different values, and observe how the list of token IDs for the first paragraph changes. What happens when you set `max_length` to a very small value? What happens when you set it to the length of the longest paragraph?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "m-AjAUdVvDjm",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "9a5638cf-a48d-43f4-8a2e-73af58faa28d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p><strong>Note:</strong> The longest paragraph has 318 tokens, but <code>max_length</code> is set to 300. Paragraphs longer than <code>max_length</code> will be truncated.</p><p></p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New length of first paragraph: 300 \n",
            "\n",
            "Padding makes the length of all sequences the same as the specified `max_length`.\n",
            "Notice the padded token IDs {tokenizer.pad_token_id} appearing at the end of the sequence.\n",
            "\n",
            "Padded tokens of first paragraph:\n",
            " [ 814  511  985 5092 4802 5183 2800 1363 4792 2134 2856 4792 1584 5092\n",
            " 2088  814 1134 3043 2922  912 2821  170 2623 4792 2023 3807 3576  912\n",
            " 1653 3772 4792 2775 1244  912 4409 3280 1030 4792 1158 3049 1992  912\n",
            " 1868 2486 2437  135 5189 3422  445 3388 2078 4849 4792 3407 2706 1259\n",
            " 4692 2856 4839 5183 4792 4078  814 3406 4259 4849 2389 4831 2707  912\n",
            " 3821 1829 3522 2134 1030 2955  185 1076 2707 3683 5143 1849 4343 1030\n",
            " 1546 1446 4983 2856 4792 2876 4078  814 3406 5092 3366 4788 2968 2151\n",
            " 2938 5092  912 1450 3522 3101  912 1672 4849 4793 4295 2721  912 5036\n",
            " 2224 3522 4792 4437 3522  513    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0]\n"
          ]
        }
      ],
      "source": [
        "# @title Set `max_length` for padding and truncating data.\n",
        "\n",
        "max_length = 300  # @param {type: \"number\"}\n",
        "\n",
        "if max_length <= 0:\n",
        "    display(\n",
        "        HTML(\n",
        "            f\"<h3>Error:</h3><p>Max length must be greater than 0. Please\"\n",
        "            f\" increase <code>max_length</code>.</p><p></p>\"\n",
        "        )\n",
        "    )\n",
        "\n",
        "elif max_length > longest_paragraph_length:\n",
        "    display(\n",
        "        HTML(\n",
        "            f\"<h3>Error:</h3><p>The padding token <code>\"\n",
        "            f\" {tokenizer.pad_token_id}</code> will be added to all\"\n",
        "            f\" sequences - you probably don't want that. Please reduce\"\n",
        "            f\" <code>max_length</code>.</p><p></p>\"\n",
        "        )\n",
        "    )\n",
        "\n",
        "else:\n",
        "    if max_length < longest_paragraph_length:\n",
        "        display(\n",
        "            HTML(\n",
        "                f\"<p><strong>Note:</strong> The longest paragraph has\"\n",
        "                f\" {longest_paragraph_length} tokens,\"\n",
        "                f\" but <code>max_length</code> is set to {max_length}.\"\n",
        "                f\" Paragraphs longer than <code>max_length</code> will be\"\n",
        "                \" truncated.</p><p></p>\"\n",
        "            )\n",
        "        )\n",
        "\n",
        "    padded_sequences = keras.preprocessing.sequence.pad_sequences(\n",
        "        encoded_tokens,\n",
        "        maxlen=max_length,\n",
        "        padding=\"post\",\n",
        "        truncating=\"post\",\n",
        "        value=tokenizer.pad_token_id,\n",
        "    )\n",
        "\n",
        "    print(\"New length of first paragraph:\", len(padded_sequences[0]), \"\\n\")\n",
        "\n",
        "    print(\n",
        "        \"Padding makes the length of all sequences the same as the specified\"\n",
        "        \" `max_length`.\"\n",
        "    )\n",
        "\n",
        "    print(\n",
        "        \"Notice the padded token IDs {tokenizer.pad_token_id} appearing at the\"\n",
        "        f\" end of the sequence.\\n\"\n",
        "    )\n",
        "    print(\"Padded tokens of first paragraph:\\n\", padded_sequences[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81N0QsKuEPhq"
      },
      "source": [
        "## Prepare input and target\n",
        "\n",
        "Recall that the task of a language model is to predict the next token given a context of previous tokens. In the case of n-gram models, you could \"teach\" the model to do this by counting n-grams in the corpus and directly computing the probabilities from the n-gram counts.\n",
        "\n",
        "Transformers have a more involved training procedure. They repeatedly make guesses of what the next token should be. If they get this guess wrong, the training procedure updates the model parameters. That way, the model is more likely to make a correct guess next time.\n",
        "\n",
        "For this training procedure, you have to prepare the data such that you have a separate *input* and *target* dataset:\n",
        "\n",
        "* **Input**: The input is a sequence of tokens that is passed into the transformer model. This may be a part of a paragraph, a full paragraph, or even multiple paragraphs, depending on how the data is structured. The input will contain everything but the last token since there is no next token for the last token.\n",
        "  \n",
        "* **Target**: The target sequence is what you want the model to predict from the input. The target will be the same as the input sequence, but *shifted left* by one token. This means the target will always contain the next token that should follow the input sequence. The target sequence will contain everything but the first word. That is because the transformer always needs at least one token as input, so it will start by predicting the next word.\n",
        "\n",
        "For example, if your dataset consists of the sentence \"Table Mountain is beautiful,\" the corresponding input and target sequences would look as follows:\n",
        "* Input: `[\"Table\", \"Mountain\", \"is\"]` (last token removed).\n",
        "* Target: `[\"Mountain\", \"is\", \"beautiful\"]` (shifted by one token).\n",
        "\n",
        "As mentioned above, the input sequence and the target sequence will actually be the corresponding token IDs instead of the raw tokens. The raw tokens are included here to make the example more readable."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the following cell to prepare the input and target sequence for training the transformer model."
      ],
      "metadata": {
        "id": "wfKPIH2uSzix"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "JLmeuOr2obyr"
      },
      "outputs": [],
      "source": [
        "# Prepare input and target for the transformer model.\n",
        "# For each example, extract all tokens except the last one.\n",
        "input_sequences = padded_sequences[:, :-1]\n",
        "# For each example, extract all tokens except the first one.\n",
        "target_sequences = padded_sequences[:, 1:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xc2IrUF-ovZN"
      },
      "source": [
        "To check that the input sequence and the target sequence have been properly prepared, print the first ten tokens in the input and the target sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "QCAQlnbrowAz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cabfbac-64c7-40c1-cbe3-8644380ec3db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 10 token IDs in first input sequence: [ 814  511  985 5092 4802 5183 2800 1363 4792 2134]\n",
            "First 10 tokens in first input sequence: The Lagos air was thick with humidity, but the energy\n",
            "\n",
            "\n",
            "First 10 token IDs in first target sequence: [ 511  985 5092 4802 5183 2800 1363 4792 2134 2856]\n",
            "First 10 tokens in target sequence: Lagos air was thick with humidity, but the energy in\n"
          ]
        }
      ],
      "source": [
        "print(\"First 10 token IDs in first input sequence:\", input_sequences[0, :10])\n",
        "print(\n",
        "    \"First 10 tokens in first input sequence:\",\n",
        "    tokenizer.decode(input_sequences[0, :10]),\n",
        ")\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"First 10 token IDs in first target sequence:\", target_sequences[0, :10])\n",
        "print(\n",
        "    \"First 10 tokens in target sequence:\",\n",
        "    tokenizer.decode(target_sequences[0, :10])\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUfcnq9qtErc"
      },
      "source": [
        "You should see in the output above that the target sequence is the input sequence shifted by one token to the left."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "107RTtKWCpV2"
      },
      "source": [
        "When you set the maximum paragraph length `max_length` previously, you were considering all tokens, including the first and the last token of each paragraph. However, in the `input_sequences`, you removed the first token from each paragraph. In the `target_sequences`, you removed the last token. So, the maximum length of the data in `input_sequences` and `target_sequences` is now one token shorter.\n",
        "\n",
        "Run the following cell to update the `max_length` variable. This variable will be used as a parameter of the transformer model and needs to accurately reflect what the length of each (padded) paragraph in your input data is."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "NWSao54yCk9M"
      },
      "outputs": [],
      "source": [
        "max_length = input_sequences.shape[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUty-eHlCTXy"
      },
      "source": [
        "## Shuffle the dataset and specify the batch size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NutUoSXCSMQI"
      },
      "source": [
        "\n",
        "-------\n",
        "> **â„¹ï¸ Info: The purpose of shuffling and batches**\n",
        ">\n",
        ">The final step before you can train your small language model is to split the data into groups of a handful of paragraphs, called **batches**. Furthermore, there is often some order in your data. For example, in the Africa Galore dataset, all examples concerning food appear one after each other. When training a model, however, it is generally best to include a very diverse set of paragraphs in one batch. This can be achieved by **shuffling** the data in the dataset so that all paragraphs appear in random order before splitting them up into batches. Note that the order of tokens within a paragraph must remain intact since you would end up with word puzzles otherwise.\n",
        ">\n",
        ">For splitting the dataset into batches, you need to define the **batch size**, that is, the number of paragraphs that should be included in one batch. Increasing the batch size usually speeds up training of the model and can also lead to better models. At the same time, however, larger batch sizes require more memory. If you set the batch size too large, you may get \"out of memory\" errors that indicate that you do not have enough memory available to train the model. You will learn more about dealing with methods for reducing memory in later courses.\n",
        ">\n",
        ">The figure below shows a dataset with seven paragraphs. Each paragraph is padded to `max_length`. In this case, it is set to the length of the longest paragraph. The dataset is then shuffled and split into batches of size 3. Note that the final batch only contains one paragraph, since the total number of paragraphs is 7 and not divisible by 3.\n",
        "> <img src='https://storage.googleapis.com/dm-educational/assets/ai_foundations/evolve_graphic.png' width='1000'>\n",
        "------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yazOaI7XVlx"
      },
      "source": [
        "The cell below implements the shuffling of the dataset and splitting it into batches. The result of this is a list of matrices referred to as **tensors**. Each matrix corresponds to a batch and contains all the token IDs for all paragraphs in that batch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "WQg55VpOw-2j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22296e98-89e8-40ce-d65b-0e866944adfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(<tf.Tensor: shape=(32, 299), dtype=int32, numpy=\n",
            "array([[ 719, 5092, 4815, ...,    0,    0,    0],\n",
            "       [ 797,  597,  912, ...,    0,    0,    0],\n",
            "       [ 470, 4084, 2932, ...,    0,    0,    0],\n",
            "       ...,\n",
            "       [ 814, 4079, 1171, ...,    0,    0,    0],\n",
            "       [ 814, 3085, 2932, ...,    0,    0,    0],\n",
            "       [ 358, 1605, 2935, ...,    0,    0,    0]], dtype=int32)>, <tf.Tensor: shape=(32, 299), dtype=int32, numpy=\n",
            "array([[5092, 4815, 4403, ...,    0,    0,    0],\n",
            "       [ 597,  912, 2364, ...,    0,    0,    0],\n",
            "       [4084, 2932,  912, ...,    0,    0,    0],\n",
            "       ...,\n",
            "       [4079, 1171, 3522, ...,    0,    0,    0],\n",
            "       [3085, 2932, 4792, ...,    0,    0,    0],\n",
            "       [1605, 2935, 2968, ...,    0,    0,    0]], dtype=int32)>)\n"
          ]
        }
      ],
      "source": [
        "# Create TensorFlow dataset to prepare sequences.\n",
        "tf_dataset = tf.data.Dataset.from_tensor_slices((input_sequences, target_sequences))\n",
        "\n",
        "# Randomly shuffle the dataset.\n",
        "# The buffer_size determines how many examples from the dataset\n",
        "# are held in memory before shuffling.\n",
        "# If you are working with a very large dataset,\n",
        "# reduce the buffer_size as needed.\n",
        "tf_dataset = tf_dataset.shuffle(buffer_size=len(input_sequences))\n",
        "\n",
        "# Specify batch size.\n",
        "batch_size = 32  # @param {type: \"number\"}\n",
        "\n",
        "# Create batches.\n",
        "batches = tf_dataset.batch(batch_size)\n",
        "\n",
        "for batch in batches.take(1):\n",
        "    print(batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVELGmoNmR3g"
      },
      "source": [
        "Run the following cell to count the total number of batches:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "0sc2lVvlktGH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66184c38-927f-45df-d306-2934fe61b2f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of batches is: 8\n"
          ]
        }
      ],
      "source": [
        "total_batches = 0\n",
        "for batch in batches:\n",
        "    total_batches += 1\n",
        "print(\"Total number of batches is:\", total_batches)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nwdEqyCfA_t"
      },
      "source": [
        "## Train a small language model (SLM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4dsdg-DtW64"
      },
      "source": [
        "You have now done all the preparatory work and are ready to train your small language model. As mentioned above, this model has around 3.5 million parameters. It is therefore  a lot smaller than so-called large language models that are used in production. For example, the Google Gemini model has billions of parameters and was trained on a much bigger dataset than the Africa Galore dataset.\n",
        "\n",
        "The size of the transformer model and the amount of training data has a strong impact on its performance. Larger models with more parameters have the capacity to learn more complex patterns and deliver better accuracy. However, they also require more computational resources, memory, and processing power. This can lead to longer training times i.e., how long the model needs to update to reach optimal performance, and higher costs. You would not be able to train a very large model in a Colab notebook. Therefore, you will be training a much smaller model here. Despite this, the overall process for training a large language model is the same as the process for training a small language model.\n",
        "\n",
        "------\n",
        "> **â„¹ï¸ Info: Parameters of a transformer model**\n",
        ">\n",
        "> **Parameters** are a set of numbers that guide the model to perform whatever task it was trained to do. In the case of transformer models, the parameters are less interpretable. They are often a very large collection of numbers that determine the model behavior.\n",
        ">\n",
        "> The parameters of a transformer model are updated after processing each batch of paragraphs. At the start of the training, the parameters are intialized with random numbers.\n",
        ">Models are then usually trained by processing the data multiple times. Going through the data once is known as an **iteration** or **epoch**. During each training iteration, the parameters are updated so that they lead to better predictions of the next token.\n",
        "------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZAHvAaAAvKI"
      },
      "source": [
        "### Initialize the model\n",
        "\n",
        "The `create_model` function used below builds a transformer model. It takes two parameters:\n",
        "\n",
        "* `max_length`: The maximum length of a paragraph in the dataset (which you set above). The model will only be able to process sequences up to this length.\n",
        "* `vocabulary_size`: The size of the vocabulary. That is the number of unique tokens in the dataset. This is used in two ways. Firstly, it is used to determine the number of unique inputs the model should expect. Secondly, it determines how many different tokens the model can predict. You can get this information from the tokenizer that you defined above by using its `vocabulary_size` property.\n",
        "* `learning_rate`: How quickly the parameters should be updated. Setting this to a higher value can speed up training but may result in a worse model. Setting this to a lower value likely improves how the model learns but may slow down training. For now, you do not have to change this value and you will learn more about this setting in later courses.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "iNGqssFqlzqE"
      },
      "outputs": [],
      "source": [
        "model = training.create_model(\n",
        "    max_length=max_length,\n",
        "    vocabulary_size=tokenizer.vocabulary_size,\n",
        "    learning_rate=1e-4\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVA4N5N9nAwB"
      },
      "source": [
        "### Initialize a callback function\n",
        "\n",
        "Training can take a while. You want to make sure that the model predictions actually get better over time. One way to do this is to define a **callback function** that is used to regularly print what the model would generate for one prompt.\n",
        "\n",
        "For example, the callback function defined in the following cell will print ten tokens for the prompt \"Abeni,\" after every 10 training iterations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "collapsed": true,
        "id": "1GhWqSRVm_ql"
      },
      "outputs": [],
      "source": [
        "prompt = \"Abeni,\"\n",
        "prompt_ids = tokenizer.encode(prompt)\n",
        "text_gen_callback = training.TextGenerator(\n",
        "    max_tokens=10, start_tokens=prompt_ids, tokenizer=tokenizer, print_every=10\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1P_McuozGX6R"
      },
      "source": [
        "### Run the training\n",
        "\n",
        "Run the following cell to train the model. As mentioned above, the training process updates the model parameter after processing each batch. This is known as a step in the training process.\n",
        "\n",
        "An epoch involves processing all batches in the dataset. Before training the model, you have to set the number of times the training process should process the datset. This is done by setting the number of epochs (`num_epochs`).\n",
        "\n",
        "You will likely get the best results if you train the model for at least 200 epochs. But if training is taking a long time, you can reduce the number of epochs. If the model does not perform well after 200 epochs, you can train it for additional epochs by adjusting the number below and re-running the cell. This will continue training your model.\n",
        "\n",
        "If you want to reset the training, re-run the previous cells before running the cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "HiJciyOo5gYU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "a3dd3732-52e1-4692-9ed4-ad0018c927eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.5903\n",
            "Epoch 2/1000\n",
            "8/8 - 0s - 40ms/step - loss: 0.5807\n",
            "Epoch 3/1000\n",
            "8/8 - 0s - 39ms/step - loss: 0.5700\n",
            "Epoch 4/1000\n",
            "8/8 - 0s - 40ms/step - loss: 0.5627\n",
            "Epoch 5/1000\n",
            "8/8 - 0s - 39ms/step - loss: 0.5591\n",
            "Epoch 6/1000\n",
            "8/8 - 0s - 39ms/step - loss: 0.5504\n",
            "Epoch 7/1000\n",
            "8/8 - 0s - 39ms/step - loss: 0.5417\n",
            "Epoch 8/1000\n",
            "8/8 - 0s - 39ms/step - loss: 0.5282\n",
            "Epoch 9/1000\n",
            "8/8 - 0s - 40ms/step - loss: 0.5193\n",
            "Epoch 10/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with long shadows is blending the a \n",
            "\n",
            "8/8 - 0s - 53ms/step - loss: 0.5080\n",
            "Epoch 11/1000\n",
            "8/8 - 0s - 39ms/step - loss: 0.4987\n",
            "Epoch 12/1000\n",
            "8/8 - 0s - 39ms/step - loss: 0.4859\n",
            "Epoch 13/1000\n",
            "8/8 - 0s - 40ms/step - loss: 0.4792\n",
            "Epoch 14/1000\n",
            "8/8 - 0s - 39ms/step - loss: 0.4688\n",
            "Epoch 15/1000\n",
            "8/8 - 0s - 40ms/step - loss: 0.4602\n",
            "Epoch 16/1000\n",
            "8/8 - 0s - 40ms/step - loss: 0.4518\n",
            "Epoch 17/1000\n",
            "8/8 - 0s - 39ms/step - loss: 0.4442\n",
            "Epoch 18/1000\n",
            "8/8 - 0s - 40ms/step - loss: 0.4360\n",
            "Epoch 19/1000\n",
            "8/8 - 0s - 40ms/step - loss: 0.4289\n",
            "Epoch 20/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with colorful during Botswana's dry climate in \n",
            "\n",
            "8/8 - 0s - 62ms/step - loss: 0.4201\n",
            "Epoch 21/1000\n",
            "8/8 - 0s - 40ms/step - loss: 0.4157\n",
            "Epoch 22/1000\n",
            "8/8 - 0s - 40ms/step - loss: 0.4083\n",
            "Epoch 23/1000\n",
            "8/8 - 0s - 40ms/step - loss: 0.4001\n",
            "Epoch 24/1000\n",
            "8/8 - 0s - 40ms/step - loss: 0.3934\n",
            "Epoch 25/1000\n",
            "8/8 - 0s - 40ms/step - loss: 0.3869\n",
            "Epoch 26/1000\n",
            "8/8 - 0s - 39ms/step - loss: 0.3804\n",
            "Epoch 27/1000\n",
            "8/8 - 0s - 40ms/step - loss: 0.3744\n",
            "Epoch 28/1000\n",
            "8/8 - 0s - 40ms/step - loss: 0.3683\n",
            "Epoch 29/1000\n",
            "8/8 - 0s - 40ms/step - loss: 0.3620\n",
            "Epoch 30/1000\n",
            "Generated text:\n",
            " Abeni, a strenuous exercise, the East 1000 a sweetened, the and \n",
            "\n",
            "8/8 - 0s - 56ms/step - loss: 0.3552\n",
            "Epoch 31/1000\n",
            "8/8 - 0s - 39ms/step - loss: 0.3495\n",
            "Epoch 32/1000\n",
            "8/8 - 0s - 40ms/step - loss: 0.3453\n",
            "Epoch 33/1000\n",
            "8/8 - 0s - 40ms/step - loss: 0.3385\n",
            "Epoch 34/1000\n",
            "8/8 - 0s - 40ms/step - loss: 0.3322\n",
            "Epoch 35/1000\n",
            "8/8 - 0s - 40ms/step - loss: 0.3257\n",
            "Epoch 36/1000\n",
            "8/8 - 0s - 40ms/step - loss: 0.3198\n",
            "Epoch 37/1000\n",
            "8/8 - 0s - 40ms/step - loss: 0.3157\n",
            "Epoch 38/1000\n",
            "8/8 - 0s - 40ms/step - loss: 0.3111\n",
            "Epoch 39/1000\n",
            "8/8 - 0s - 40ms/step - loss: 0.3045\n",
            "Epoch 40/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with sea, often enjoyed production, beings. scholarship \n",
            "\n",
            "8/8 - 0s - 55ms/step - loss: 0.3007\n",
            "Epoch 41/1000\n",
            "8/8 - 0s - 40ms/step - loss: 0.2951\n",
            "Epoch 42/1000\n",
            "8/8 - 0s - 40ms/step - loss: 0.2905\n",
            "Epoch 43/1000\n",
            "8/8 - 0s - 40ms/step - loss: 0.2830\n",
            "Epoch 44/1000\n",
            "8/8 - 0s - 40ms/step - loss: 0.2800\n",
            "Epoch 45/1000\n",
            "8/8 - 0s - 40ms/step - loss: 0.2756\n",
            "Epoch 46/1000\n",
            "8/8 - 0s - 40ms/step - loss: 0.2714\n",
            "Epoch 47/1000\n",
            "8/8 - 0s - 41ms/step - loss: 0.2680\n",
            "Epoch 48/1000\n",
            "8/8 - 0s - 41ms/step - loss: 0.2636\n",
            "Epoch 49/1000\n",
            "8/8 - 0s - 40ms/step - loss: 0.2592\n",
            "Epoch 50/1000\n",
            "Generated text:\n",
            " Abeni, a sculpture, from Ethiopia, millet or climates, from arid fabric \n",
            "\n",
            "8/8 - 0s - 55ms/step - loss: 0.2542\n",
            "Epoch 51/1000\n",
            "8/8 - 0s - 40ms/step - loss: 0.2508\n",
            "Epoch 52/1000\n",
            "8/8 - 0s - 41ms/step - loss: 0.2455\n",
            "Epoch 53/1000\n",
            "8/8 - 0s - 41ms/step - loss: 0.2430\n",
            "Epoch 54/1000\n",
            "8/8 - 0s - 40ms/step - loss: 0.2387\n",
            "Epoch 55/1000\n",
            "8/8 - 0s - 41ms/step - loss: 0.2350\n",
            "Epoch 56/1000\n",
            "8/8 - 0s - 41ms/step - loss: 0.2317\n",
            "Epoch 57/1000\n",
            "8/8 - 0s - 40ms/step - loss: 0.2269\n",
            "Epoch 58/1000\n",
            "8/8 - 0s - 41ms/step - loss: 0.2243\n",
            "Epoch 59/1000\n",
            "8/8 - 0s - 41ms/step - loss: 0.2215\n",
            "Epoch 60/1000\n",
            "Generated text:\n",
            " Abeni, a resist-dyed historic equines, closely linked to a potjiekos is \n",
            "\n",
            "8/8 - 0s - 56ms/step - loss: 0.2176\n",
            "Epoch 61/1000\n",
            "8/8 - 0s - 40ms/step - loss: 0.2145\n",
            "Epoch 62/1000\n",
            "8/8 - 0s - 41ms/step - loss: 0.2118\n",
            "Epoch 63/1000\n",
            "8/8 - 0s - 41ms/step - loss: 0.2086\n",
            "Epoch 64/1000\n",
            "8/8 - 0s - 41ms/step - loss: 0.2052\n",
            "Epoch 65/1000\n",
            "8/8 - 0s - 41ms/step - loss: 0.2024\n",
            "Epoch 66/1000\n",
            "8/8 - 0s - 41ms/step - loss: 0.1987\n",
            "Epoch 67/1000\n",
            "8/8 - 0s - 41ms/step - loss: 0.1963\n",
            "Epoch 68/1000\n",
            "8/8 - 0s - 41ms/step - loss: 0.1919\n",
            "Epoch 69/1000\n",
            "8/8 - 0s - 41ms/step - loss: 0.1906\n",
            "Epoch 70/1000\n",
            "Generated text:\n",
            " Abeni, a strenuous organs excellent camouflage from agriculture a set. UNESCO \n",
            "\n",
            "8/8 - 0s - 55ms/step - loss: 0.1884\n",
            "Epoch 71/1000\n",
            "8/8 - 0s - 40ms/step - loss: 0.1856\n",
            "Epoch 72/1000\n",
            "8/8 - 0s - 42ms/step - loss: 0.1836\n",
            "Epoch 73/1000\n",
            "8/8 - 0s - 41ms/step - loss: 0.1802\n",
            "Epoch 74/1000\n",
            "8/8 - 0s - 42ms/step - loss: 0.1765\n",
            "Epoch 75/1000\n",
            "8/8 - 0s - 41ms/step - loss: 0.1746\n",
            "Epoch 76/1000\n",
            "8/8 - 0s - 42ms/step - loss: 0.1724\n",
            "Epoch 77/1000\n",
            "8/8 - 0s - 42ms/step - loss: 0.1694\n",
            "Epoch 78/1000\n",
            "8/8 - 0s - 41ms/step - loss: 0.1673\n",
            "Epoch 79/1000\n",
            "8/8 - 0s - 42ms/step - loss: 0.1649\n",
            "Epoch 80/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with braids adorned with \n",
            "\n",
            "8/8 - 0s - 57ms/step - loss: 0.1627\n",
            "Epoch 81/1000\n",
            "8/8 - 0s - 41ms/step - loss: 0.1609\n",
            "Epoch 82/1000\n",
            "8/8 - 0s - 42ms/step - loss: 0.1579\n",
            "Epoch 83/1000\n",
            "8/8 - 0s - 42ms/step - loss: 0.1566\n",
            "Epoch 84/1000\n",
            "8/8 - 0s - 42ms/step - loss: 0.1537\n",
            "Epoch 85/1000\n",
            "8/8 - 0s - 41ms/step - loss: 0.1522\n",
            "Epoch 86/1000\n",
            "8/8 - 0s - 42ms/step - loss: 0.1505\n",
            "Epoch 87/1000\n",
            "8/8 - 0s - 42ms/step - loss: 0.1483\n",
            "Epoch 88/1000\n",
            "8/8 - 0s - 42ms/step - loss: 0.1462\n",
            "Epoch 89/1000\n",
            "8/8 - 0s - 42ms/step - loss: 0.1444\n",
            "Epoch 90/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with savory Moroccan soup from colorful patterns, \n",
            "\n",
            "8/8 - 0s - 57ms/step - loss: 0.1429\n",
            "Epoch 91/1000\n",
            "8/8 - 0s - 41ms/step - loss: 0.1400\n",
            "Epoch 92/1000\n",
            "8/8 - 0s - 41ms/step - loss: 0.1389\n",
            "Epoch 93/1000\n",
            "8/8 - 0s - 42ms/step - loss: 0.1380\n",
            "Epoch 94/1000\n",
            "8/8 - 0s - 42ms/step - loss: 0.1356\n",
            "Epoch 95/1000\n",
            "8/8 - 0s - 42ms/step - loss: 0.1341\n",
            "Epoch 96/1000\n",
            "8/8 - 0s - 41ms/step - loss: 0.1337\n",
            "Epoch 97/1000\n",
            "8/8 - 0s - 42ms/step - loss: 0.1324\n",
            "Epoch 98/1000\n",
            "8/8 - 0s - 42ms/step - loss: 0.1319\n",
            "Epoch 99/1000\n",
            "8/8 - 0s - 42ms/step - loss: 0.1296\n",
            "Epoch 100/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 0s - 56ms/step - loss: 0.1272\n",
            "Epoch 101/1000\n",
            "8/8 - 0s - 41ms/step - loss: 0.1254\n",
            "Epoch 102/1000\n",
            "8/8 - 0s - 42ms/step - loss: 0.1240\n",
            "Epoch 103/1000\n",
            "8/8 - 0s - 42ms/step - loss: 0.1227\n",
            "Epoch 104/1000\n",
            "8/8 - 0s - 42ms/step - loss: 0.1207\n",
            "Epoch 105/1000\n",
            "8/8 - 0s - 42ms/step - loss: 0.1192\n",
            "Epoch 106/1000\n",
            "8/8 - 0s - 41ms/step - loss: 0.1172\n",
            "Epoch 107/1000\n",
            "8/8 - 0s - 42ms/step - loss: 0.1162\n",
            "Epoch 108/1000\n",
            "8/8 - 0s - 42ms/step - loss: 0.1148\n",
            "Epoch 109/1000\n",
            "8/8 - 0s - 41ms/step - loss: 0.1135\n",
            "Epoch 110/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with love for a \n",
            "\n",
            "8/8 - 0s - 57ms/step - loss: 0.1126\n",
            "Epoch 111/1000\n",
            "8/8 - 0s - 42ms/step - loss: 0.1110\n",
            "Epoch 112/1000\n",
            "8/8 - 0s - 42ms/step - loss: 0.1102\n",
            "Epoch 113/1000\n",
            "8/8 - 0s - 42ms/step - loss: 0.1084\n",
            "Epoch 114/1000\n",
            "8/8 - 0s - 41ms/step - loss: 0.1074\n",
            "Epoch 115/1000\n",
            "8/8 - 0s - 42ms/step - loss: 0.1062\n",
            "Epoch 116/1000\n",
            "8/8 - 0s - 42ms/step - loss: 0.1049\n",
            "Epoch 117/1000\n",
            "8/8 - 0s - 41ms/step - loss: 0.1035\n",
            "Epoch 118/1000\n",
            "8/8 - 0s - 42ms/step - loss: 0.1026\n",
            "Epoch 119/1000\n",
            "8/8 - 0s - 42ms/step - loss: 0.1018\n",
            "Epoch 120/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with colorful fritters that reddish-orange color and \n",
            "\n",
            "8/8 - 1s - 65ms/step - loss: 0.1007\n",
            "Epoch 121/1000\n",
            "8/8 - 0s - 41ms/step - loss: 0.0998\n",
            "Epoch 122/1000\n",
            "8/8 - 0s - 41ms/step - loss: 0.0987\n",
            "Epoch 123/1000\n",
            "8/8 - 0s - 42ms/step - loss: 0.0977\n",
            "Epoch 124/1000\n",
            "8/8 - 0s - 42ms/step - loss: 0.0966\n",
            "Epoch 125/1000\n",
            "8/8 - 0s - 42ms/step - loss: 0.0957\n",
            "Epoch 126/1000\n",
            "8/8 - 0s - 42ms/step - loss: 0.0956\n",
            "Epoch 127/1000\n",
            "8/8 - 0s - 42ms/step - loss: 0.0944\n",
            "Epoch 128/1000\n",
            "8/8 - 0s - 42ms/step - loss: 0.0930\n",
            "Epoch 129/1000\n",
            "8/8 - 0s - 42ms/step - loss: 0.0932\n",
            "Epoch 130/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with enticing to balance \n",
            "\n",
            "8/8 - 0s - 56ms/step - loss: 0.0913\n",
            "Epoch 131/1000\n",
            "8/8 - 0s - 42ms/step - loss: 0.0907\n",
            "Epoch 132/1000\n",
            "8/8 - 0s - 42ms/step - loss: 0.0897\n",
            "Epoch 133/1000\n",
            "8/8 - 0s - 42ms/step - loss: 0.0887\n",
            "Epoch 134/1000\n",
            "8/8 - 0s - 42ms/step - loss: 0.0877\n",
            "Epoch 135/1000\n",
            "8/8 - 0s - 42ms/step - loss: 0.0864\n",
            "Epoch 136/1000\n",
            "8/8 - 0s - 42ms/step - loss: 0.0860\n",
            "Epoch 137/1000\n",
            "8/8 - 0s - 42ms/step - loss: 0.0854\n",
            "Epoch 138/1000\n",
            "8/8 - 0s - 42ms/step - loss: 0.0843\n",
            "Epoch 139/1000\n",
            "8/8 - 0s - 42ms/step - loss: 0.0833\n",
            "Epoch 140/1000\n",
            "Generated text:\n",
            " Abeni, a printed cotton fabric characterized by intricate geometric cooked in \n",
            "\n",
            "8/8 - 0s - 56ms/step - loss: 0.0830\n",
            "Epoch 141/1000\n",
            "8/8 - 0s - 41ms/step - loss: 0.0821\n",
            "Epoch 142/1000\n",
            "8/8 - 0s - 42ms/step - loss: 0.0811\n",
            "Epoch 143/1000\n",
            "8/8 - 0s - 42ms/step - loss: 0.0803\n",
            "Epoch 144/1000\n",
            "8/8 - 0s - 43ms/step - loss: 0.0799\n",
            "Epoch 145/1000\n",
            "8/8 - 0s - 42ms/step - loss: 0.0792\n",
            "Epoch 146/1000\n",
            "8/8 - 0s - 43ms/step - loss: 0.0784\n",
            "Epoch 147/1000\n",
            "8/8 - 0s - 42ms/step - loss: 0.0776\n",
            "Epoch 148/1000\n",
            "8/8 - 0s - 43ms/step - loss: 0.0772\n",
            "Epoch 149/1000\n",
            "8/8 - 0s - 43ms/step - loss: 0.0766\n",
            "Epoch 150/1000\n",
            "Generated text:\n",
            " Abeni, a strenuous day examples include the a fields, stumbled upon \n",
            "\n",
            "8/8 - 0s - 62ms/step - loss: 0.0759\n",
            "Epoch 151/1000\n",
            "8/8 - 0s - 42ms/step - loss: 0.0752\n",
            "Epoch 152/1000\n",
            "8/8 - 0s - 43ms/step - loss: 0.0745\n",
            "Epoch 153/1000\n",
            "8/8 - 0s - 43ms/step - loss: 0.0741\n",
            "Epoch 154/1000\n",
            "8/8 - 0s - 43ms/step - loss: 0.0735\n",
            "Epoch 155/1000\n",
            "8/8 - 0s - 43ms/step - loss: 0.0728\n",
            "Epoch 156/1000\n",
            "8/8 - 0s - 43ms/step - loss: 0.0720\n",
            "Epoch 157/1000\n",
            "8/8 - 0s - 43ms/step - loss: 0.0715\n",
            "Epoch 158/1000\n",
            "8/8 - 0s - 42ms/step - loss: 0.0709\n",
            "Epoch 159/1000\n",
            "8/8 - 0s - 43ms/step - loss: 0.0701\n",
            "Epoch 160/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 0s - 58ms/step - loss: 0.0698\n",
            "Epoch 161/1000\n",
            "8/8 - 0s - 42ms/step - loss: 0.0691\n",
            "Epoch 162/1000\n",
            "8/8 - 0s - 43ms/step - loss: 0.0689\n",
            "Epoch 163/1000\n",
            "8/8 - 0s - 43ms/step - loss: 0.0691\n",
            "Epoch 164/1000\n",
            "8/8 - 0s - 43ms/step - loss: 0.0678\n",
            "Epoch 165/1000\n",
            "8/8 - 0s - 43ms/step - loss: 0.0671\n",
            "Epoch 166/1000\n",
            "8/8 - 0s - 43ms/step - loss: 0.0666\n",
            "Epoch 167/1000\n",
            "8/8 - 0s - 43ms/step - loss: 0.0659\n",
            "Epoch 168/1000\n",
            "8/8 - 0s - 43ms/step - loss: 0.0656\n",
            "Epoch 169/1000\n",
            "8/8 - 0s - 43ms/step - loss: 0.0652\n",
            "Epoch 170/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with braids adorned with \n",
            "\n",
            "8/8 - 0s - 58ms/step - loss: 0.0644\n",
            "Epoch 171/1000\n",
            "8/8 - 0s - 43ms/step - loss: 0.0642\n",
            "Epoch 172/1000\n",
            "8/8 - 0s - 43ms/step - loss: 0.0635\n",
            "Epoch 173/1000\n",
            "8/8 - 0s - 43ms/step - loss: 0.0628\n",
            "Epoch 174/1000\n",
            "8/8 - 0s - 43ms/step - loss: 0.0624\n",
            "Epoch 175/1000\n",
            "8/8 - 0s - 43ms/step - loss: 0.0621\n",
            "Epoch 176/1000\n",
            "8/8 - 0s - 43ms/step - loss: 0.0614\n",
            "Epoch 177/1000\n",
            "8/8 - 0s - 44ms/step - loss: 0.0608\n",
            "Epoch 178/1000\n",
            "8/8 - 0s - 43ms/step - loss: 0.0603\n",
            "Epoch 179/1000\n",
            "8/8 - 0s - 43ms/step - loss: 0.0600\n",
            "Epoch 180/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 0s - 59ms/step - loss: 0.0600\n",
            "Epoch 181/1000\n",
            "8/8 - 0s - 42ms/step - loss: 0.0594\n",
            "Epoch 182/1000\n",
            "8/8 - 0s - 43ms/step - loss: 0.0588\n",
            "Epoch 183/1000\n",
            "8/8 - 0s - 44ms/step - loss: 0.0582\n",
            "Epoch 184/1000\n",
            "8/8 - 0s - 44ms/step - loss: 0.0578\n",
            "Epoch 185/1000\n",
            "8/8 - 0s - 44ms/step - loss: 0.0573\n",
            "Epoch 186/1000\n",
            "8/8 - 0s - 44ms/step - loss: 0.0575\n",
            "Epoch 187/1000\n",
            "8/8 - 0s - 43ms/step - loss: 0.0570\n",
            "Epoch 188/1000\n",
            "8/8 - 0s - 43ms/step - loss: 0.0563\n",
            "Epoch 189/1000\n",
            "8/8 - 0s - 43ms/step - loss: 0.0560\n",
            "Epoch 190/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 0s - 58ms/step - loss: 0.0557\n",
            "Epoch 191/1000\n",
            "8/8 - 0s - 43ms/step - loss: 0.0552\n",
            "Epoch 192/1000\n",
            "8/8 - 0s - 44ms/step - loss: 0.0551\n",
            "Epoch 193/1000\n",
            "8/8 - 0s - 43ms/step - loss: 0.0547\n",
            "Epoch 194/1000\n",
            "8/8 - 0s - 44ms/step - loss: 0.0542\n",
            "Epoch 195/1000\n",
            "8/8 - 0s - 43ms/step - loss: 0.0540\n",
            "Epoch 196/1000\n",
            "8/8 - 0s - 44ms/step - loss: 0.0536\n",
            "Epoch 197/1000\n",
            "8/8 - 0s - 43ms/step - loss: 0.0532\n",
            "Epoch 198/1000\n",
            "8/8 - 0s - 43ms/step - loss: 0.0528\n",
            "Epoch 199/1000\n",
            "8/8 - 0s - 44ms/step - loss: 0.0521\n",
            "Epoch 200/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 0s - 58ms/step - loss: 0.0521\n",
            "Epoch 201/1000\n",
            "8/8 - 0s - 43ms/step - loss: 0.0514\n",
            "Epoch 202/1000\n",
            "8/8 - 0s - 44ms/step - loss: 0.0514\n",
            "Epoch 203/1000\n",
            "8/8 - 0s - 44ms/step - loss: 0.0518\n",
            "Epoch 204/1000\n",
            "8/8 - 0s - 43ms/step - loss: 0.0513\n",
            "Epoch 205/1000\n",
            "8/8 - 0s - 44ms/step - loss: 0.0515\n",
            "Epoch 206/1000\n",
            "8/8 - 0s - 44ms/step - loss: 0.0504\n",
            "Epoch 207/1000\n",
            "8/8 - 0s - 44ms/step - loss: 0.0501\n",
            "Epoch 208/1000\n",
            "8/8 - 0s - 43ms/step - loss: 0.0498\n",
            "Epoch 209/1000\n",
            "8/8 - 0s - 44ms/step - loss: 0.0499\n",
            "Epoch 210/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with sparkling fauna. It is textile in \n",
            "\n",
            "8/8 - 0s - 59ms/step - loss: 0.0494\n",
            "Epoch 211/1000\n",
            "8/8 - 0s - 44ms/step - loss: 0.0488\n",
            "Epoch 212/1000\n",
            "8/8 - 0s - 44ms/step - loss: 0.0487\n",
            "Epoch 213/1000\n",
            "8/8 - 0s - 44ms/step - loss: 0.0488\n",
            "Epoch 214/1000\n",
            "8/8 - 0s - 45ms/step - loss: 0.0477\n",
            "Epoch 215/1000\n",
            "8/8 - 0s - 44ms/step - loss: 0.0478\n",
            "Epoch 216/1000\n",
            "8/8 - 0s - 45ms/step - loss: 0.0471\n",
            "Epoch 217/1000\n",
            "8/8 - 0s - 44ms/step - loss: 0.0466\n",
            "Epoch 218/1000\n",
            "8/8 - 0s - 45ms/step - loss: 0.0468\n",
            "Epoch 219/1000\n",
            "8/8 - 0s - 44ms/step - loss: 0.0465\n",
            "Epoch 220/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 0s - 59ms/step - loss: 0.0461\n",
            "Epoch 221/1000\n",
            "8/8 - 0s - 43ms/step - loss: 0.0462\n",
            "Epoch 222/1000\n",
            "8/8 - 0s - 44ms/step - loss: 0.0457\n",
            "Epoch 223/1000\n",
            "8/8 - 0s - 45ms/step - loss: 0.0457\n",
            "Epoch 224/1000\n",
            "8/8 - 0s - 44ms/step - loss: 0.0454\n",
            "Epoch 225/1000\n",
            "8/8 - 0s - 44ms/step - loss: 0.0452\n",
            "Epoch 226/1000\n",
            "8/8 - 0s - 45ms/step - loss: 0.0447\n",
            "Epoch 227/1000\n",
            "8/8 - 0s - 45ms/step - loss: 0.0444\n",
            "Epoch 228/1000\n",
            "8/8 - 0s - 44ms/step - loss: 0.0442\n",
            "Epoch 229/1000\n",
            "8/8 - 0s - 45ms/step - loss: 0.0441\n",
            "Epoch 230/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 0s - 59ms/step - loss: 0.0436\n",
            "Epoch 231/1000\n",
            "8/8 - 0s - 44ms/step - loss: 0.0435\n",
            "Epoch 232/1000\n",
            "8/8 - 0s - 45ms/step - loss: 0.0433\n",
            "Epoch 233/1000\n",
            "8/8 - 0s - 44ms/step - loss: 0.0432\n",
            "Epoch 234/1000\n",
            "8/8 - 0s - 44ms/step - loss: 0.0428\n",
            "Epoch 235/1000\n",
            "8/8 - 0s - 45ms/step - loss: 0.0423\n",
            "Epoch 236/1000\n",
            "8/8 - 0s - 45ms/step - loss: 0.0425\n",
            "Epoch 237/1000\n",
            "8/8 - 0s - 45ms/step - loss: 0.0422\n",
            "Epoch 238/1000\n",
            "8/8 - 0s - 45ms/step - loss: 0.0421\n",
            "Epoch 239/1000\n",
            "8/8 - 0s - 45ms/step - loss: 0.0412\n",
            "Epoch 240/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with sparkling eyes and \n",
            "\n",
            "8/8 - 0s - 58ms/step - loss: 0.0413\n",
            "Epoch 241/1000\n",
            "8/8 - 0s - 43ms/step - loss: 0.0409\n",
            "Epoch 242/1000\n",
            "8/8 - 0s - 45ms/step - loss: 0.0409\n",
            "Epoch 243/1000\n",
            "8/8 - 0s - 45ms/step - loss: 0.0407\n",
            "Epoch 244/1000\n",
            "8/8 - 0s - 45ms/step - loss: 0.0403\n",
            "Epoch 245/1000\n",
            "8/8 - 0s - 45ms/step - loss: 0.0404\n",
            "Epoch 246/1000\n",
            "8/8 - 0s - 45ms/step - loss: 0.0402\n",
            "Epoch 247/1000\n",
            "8/8 - 0s - 45ms/step - loss: 0.0398\n",
            "Epoch 248/1000\n",
            "8/8 - 0s - 45ms/step - loss: 0.0397\n",
            "Epoch 249/1000\n",
            "8/8 - 0s - 45ms/step - loss: 0.0393\n",
            "Epoch 250/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 0s - 59ms/step - loss: 0.0392\n",
            "Epoch 251/1000\n",
            "8/8 - 0s - 44ms/step - loss: 0.0391\n",
            "Epoch 252/1000\n",
            "8/8 - 0s - 45ms/step - loss: 0.0391\n",
            "Epoch 253/1000\n",
            "8/8 - 0s - 45ms/step - loss: 0.0388\n",
            "Epoch 254/1000\n",
            "8/8 - 0s - 45ms/step - loss: 0.0390\n",
            "Epoch 255/1000\n",
            "8/8 - 0s - 45ms/step - loss: 0.0382\n",
            "Epoch 256/1000\n",
            "8/8 - 0s - 45ms/step - loss: 0.0379\n",
            "Epoch 257/1000\n",
            "8/8 - 0s - 45ms/step - loss: 0.0380\n",
            "Epoch 258/1000\n",
            "8/8 - 0s - 45ms/step - loss: 0.0375\n",
            "Epoch 259/1000\n",
            "8/8 - 0s - 45ms/step - loss: 0.0373\n",
            "Epoch 260/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with braids adorned with \n",
            "\n",
            "8/8 - 0s - 60ms/step - loss: 0.0377\n",
            "Epoch 261/1000\n",
            "8/8 - 0s - 44ms/step - loss: 0.0371\n",
            "Epoch 262/1000\n",
            "8/8 - 0s - 45ms/step - loss: 0.0374\n",
            "Epoch 263/1000\n",
            "8/8 - 0s - 45ms/step - loss: 0.0367\n",
            "Epoch 264/1000\n",
            "8/8 - 0s - 45ms/step - loss: 0.0365\n",
            "Epoch 265/1000\n",
            "8/8 - 0s - 45ms/step - loss: 0.0365\n",
            "Epoch 266/1000\n",
            "8/8 - 0s - 46ms/step - loss: 0.0363\n",
            "Epoch 267/1000\n",
            "8/8 - 0s - 45ms/step - loss: 0.0363\n",
            "Epoch 268/1000\n",
            "8/8 - 0s - 45ms/step - loss: 0.0359\n",
            "Epoch 269/1000\n",
            "8/8 - 0s - 45ms/step - loss: 0.0358\n",
            "Epoch 270/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 0s - 60ms/step - loss: 0.0357\n",
            "Epoch 271/1000\n",
            "8/8 - 0s - 44ms/step - loss: 0.0359\n",
            "Epoch 272/1000\n",
            "8/8 - 0s - 45ms/step - loss: 0.0357\n",
            "Epoch 273/1000\n",
            "8/8 - 0s - 45ms/step - loss: 0.0352\n",
            "Epoch 274/1000\n",
            "8/8 - 0s - 45ms/step - loss: 0.0352\n",
            "Epoch 275/1000\n",
            "8/8 - 0s - 45ms/step - loss: 0.0350\n",
            "Epoch 276/1000\n",
            "8/8 - 0s - 46ms/step - loss: 0.0349\n",
            "Epoch 277/1000\n",
            "8/8 - 0s - 46ms/step - loss: 0.0347\n",
            "Epoch 278/1000\n",
            "8/8 - 0s - 45ms/step - loss: 0.0344\n",
            "Epoch 279/1000\n",
            "8/8 - 0s - 46ms/step - loss: 0.0344\n",
            "Epoch 280/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with braids adorned with \n",
            "\n",
            "8/8 - 0s - 60ms/step - loss: 0.0344\n",
            "Epoch 281/1000\n",
            "8/8 - 0s - 45ms/step - loss: 0.0345\n",
            "Epoch 282/1000\n",
            "8/8 - 0s - 46ms/step - loss: 0.0338\n",
            "Epoch 283/1000\n",
            "8/8 - 0s - 46ms/step - loss: 0.0338\n",
            "Epoch 284/1000\n",
            "8/8 - 0s - 45ms/step - loss: 0.0336\n",
            "Epoch 285/1000\n",
            "8/8 - 0s - 45ms/step - loss: 0.0342\n",
            "Epoch 286/1000\n",
            "8/8 - 0s - 45ms/step - loss: 0.0338\n",
            "Epoch 287/1000\n",
            "8/8 - 0s - 45ms/step - loss: 0.0336\n",
            "Epoch 288/1000\n",
            "8/8 - 0s - 45ms/step - loss: 0.0334\n",
            "Epoch 289/1000\n",
            "8/8 - 0s - 46ms/step - loss: 0.0330\n",
            "Epoch 290/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 0s - 62ms/step - loss: 0.0328\n",
            "Epoch 291/1000\n",
            "8/8 - 0s - 45ms/step - loss: 0.0327\n",
            "Epoch 292/1000\n",
            "8/8 - 0s - 46ms/step - loss: 0.0326\n",
            "Epoch 293/1000\n",
            "8/8 - 0s - 46ms/step - loss: 0.0326\n",
            "Epoch 294/1000\n",
            "8/8 - 0s - 46ms/step - loss: 0.0328\n",
            "Epoch 295/1000\n",
            "8/8 - 0s - 46ms/step - loss: 0.0321\n",
            "Epoch 296/1000\n",
            "8/8 - 0s - 46ms/step - loss: 0.0319\n",
            "Epoch 297/1000\n",
            "8/8 - 0s - 46ms/step - loss: 0.0322\n",
            "Epoch 298/1000\n",
            "8/8 - 0s - 46ms/step - loss: 0.0319\n",
            "Epoch 299/1000\n",
            "8/8 - 0s - 46ms/step - loss: 0.0318\n",
            "Epoch 300/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids teff, bright golden, then steamed \n",
            "\n",
            "8/8 - 0s - 61ms/step - loss: 0.0315\n",
            "Epoch 301/1000\n",
            "8/8 - 0s - 45ms/step - loss: 0.0317\n",
            "Epoch 302/1000\n",
            "8/8 - 0s - 46ms/step - loss: 0.0311\n",
            "Epoch 303/1000\n",
            "8/8 - 0s - 46ms/step - loss: 0.0310\n",
            "Epoch 304/1000\n",
            "8/8 - 0s - 46ms/step - loss: 0.0309\n",
            "Epoch 305/1000\n",
            "8/8 - 0s - 46ms/step - loss: 0.0307\n",
            "Epoch 306/1000\n",
            "8/8 - 0s - 46ms/step - loss: 0.0311\n",
            "Epoch 307/1000\n",
            "8/8 - 0s - 46ms/step - loss: 0.0310\n",
            "Epoch 308/1000\n",
            "8/8 - 0s - 46ms/step - loss: 0.0310\n",
            "Epoch 309/1000\n",
            "8/8 - 0s - 46ms/step - loss: 0.0309\n",
            "Epoch 310/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 0s - 60ms/step - loss: 0.0305\n",
            "Epoch 311/1000\n",
            "8/8 - 0s - 45ms/step - loss: 0.0301\n",
            "Epoch 312/1000\n",
            "8/8 - 0s - 46ms/step - loss: 0.0303\n",
            "Epoch 313/1000\n",
            "8/8 - 0s - 46ms/step - loss: 0.0296\n",
            "Epoch 314/1000\n",
            "8/8 - 0s - 46ms/step - loss: 0.0298\n",
            "Epoch 315/1000\n",
            "8/8 - 0s - 46ms/step - loss: 0.0295\n",
            "Epoch 316/1000\n",
            "8/8 - 0s - 46ms/step - loss: 0.0294\n",
            "Epoch 317/1000\n",
            "8/8 - 0s - 46ms/step - loss: 0.0294\n",
            "Epoch 318/1000\n",
            "8/8 - 0s - 46ms/step - loss: 0.0295\n",
            "Epoch 319/1000\n",
            "8/8 - 0s - 46ms/step - loss: 0.0297\n",
            "Epoch 320/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 0s - 62ms/step - loss: 0.0292\n",
            "Epoch 321/1000\n",
            "8/8 - 0s - 45ms/step - loss: 0.0290\n",
            "Epoch 322/1000\n",
            "8/8 - 0s - 46ms/step - loss: 0.0292\n",
            "Epoch 323/1000\n",
            "8/8 - 0s - 46ms/step - loss: 0.0288\n",
            "Epoch 324/1000\n",
            "8/8 - 0s - 46ms/step - loss: 0.0286\n",
            "Epoch 325/1000\n",
            "8/8 - 0s - 46ms/step - loss: 0.0285\n",
            "Epoch 326/1000\n",
            "8/8 - 0s - 47ms/step - loss: 0.0285\n",
            "Epoch 327/1000\n",
            "8/8 - 0s - 46ms/step - loss: 0.0282\n",
            "Epoch 328/1000\n",
            "8/8 - 0s - 46ms/step - loss: 0.0281\n",
            "Epoch 329/1000\n",
            "8/8 - 0s - 46ms/step - loss: 0.0283\n",
            "Epoch 330/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 0s - 61ms/step - loss: 0.0280\n",
            "Epoch 331/1000\n",
            "8/8 - 0s - 45ms/step - loss: 0.0277\n",
            "Epoch 332/1000\n",
            "8/8 - 0s - 47ms/step - loss: 0.0278\n",
            "Epoch 333/1000\n",
            "8/8 - 0s - 47ms/step - loss: 0.0277\n",
            "Epoch 334/1000\n",
            "8/8 - 0s - 47ms/step - loss: 0.0280\n",
            "Epoch 335/1000\n",
            "8/8 - 0s - 47ms/step - loss: 0.0275\n",
            "Epoch 336/1000\n",
            "8/8 - 0s - 47ms/step - loss: 0.0275\n",
            "Epoch 337/1000\n",
            "8/8 - 0s - 47ms/step - loss: 0.0273\n",
            "Epoch 338/1000\n",
            "8/8 - 0s - 47ms/step - loss: 0.0274\n",
            "Epoch 339/1000\n",
            "8/8 - 0s - 47ms/step - loss: 0.0274\n",
            "Epoch 340/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 0s - 61ms/step - loss: 0.0275\n",
            "Epoch 341/1000\n",
            "8/8 - 0s - 46ms/step - loss: 0.0271\n",
            "Epoch 342/1000\n",
            "8/8 - 0s - 47ms/step - loss: 0.0268\n",
            "Epoch 343/1000\n",
            "8/8 - 0s - 47ms/step - loss: 0.0274\n",
            "Epoch 344/1000\n",
            "8/8 - 0s - 47ms/step - loss: 0.0270\n",
            "Epoch 345/1000\n",
            "8/8 - 0s - 47ms/step - loss: 0.0267\n",
            "Epoch 346/1000\n",
            "8/8 - 0s - 47ms/step - loss: 0.0266\n",
            "Epoch 347/1000\n",
            "8/8 - 0s - 47ms/step - loss: 0.0265\n",
            "Epoch 348/1000\n",
            "8/8 - 0s - 47ms/step - loss: 0.0265\n",
            "Epoch 349/1000\n",
            "8/8 - 0s - 47ms/step - loss: 0.0266\n",
            "Epoch 350/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 1s - 64ms/step - loss: 0.0264\n",
            "Epoch 351/1000\n",
            "8/8 - 0s - 46ms/step - loss: 0.0263\n",
            "Epoch 352/1000\n",
            "8/8 - 0s - 47ms/step - loss: 0.0262\n",
            "Epoch 353/1000\n",
            "8/8 - 0s - 47ms/step - loss: 0.0261\n",
            "Epoch 354/1000\n",
            "8/8 - 0s - 47ms/step - loss: 0.0261\n",
            "Epoch 355/1000\n",
            "8/8 - 0s - 47ms/step - loss: 0.0263\n",
            "Epoch 356/1000\n",
            "8/8 - 0s - 47ms/step - loss: 0.0259\n",
            "Epoch 357/1000\n",
            "8/8 - 0s - 47ms/step - loss: 0.0260\n",
            "Epoch 358/1000\n",
            "8/8 - 0s - 47ms/step - loss: 0.0260\n",
            "Epoch 359/1000\n",
            "8/8 - 0s - 47ms/step - loss: 0.0255\n",
            "Epoch 360/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 0s - 62ms/step - loss: 0.0255\n",
            "Epoch 361/1000\n",
            "8/8 - 0s - 46ms/step - loss: 0.0255\n",
            "Epoch 362/1000\n",
            "8/8 - 0s - 47ms/step - loss: 0.0253\n",
            "Epoch 363/1000\n",
            "8/8 - 0s - 47ms/step - loss: 0.0256\n",
            "Epoch 364/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0255\n",
            "Epoch 365/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0252\n",
            "Epoch 366/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0250\n",
            "Epoch 367/1000\n",
            "8/8 - 0s - 47ms/step - loss: 0.0250\n",
            "Epoch 368/1000\n",
            "8/8 - 0s - 47ms/step - loss: 0.0252\n",
            "Epoch 369/1000\n",
            "8/8 - 0s - 47ms/step - loss: 0.0251\n",
            "Epoch 370/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 1s - 63ms/step - loss: 0.0247\n",
            "Epoch 371/1000\n",
            "8/8 - 0s - 46ms/step - loss: 0.0248\n",
            "Epoch 372/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0248\n",
            "Epoch 373/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0244\n",
            "Epoch 374/1000\n",
            "8/8 - 0s - 47ms/step - loss: 0.0245\n",
            "Epoch 375/1000\n",
            "8/8 - 0s - 47ms/step - loss: 0.0246\n",
            "Epoch 376/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0247\n",
            "Epoch 377/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0243\n",
            "Epoch 378/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0246\n",
            "Epoch 379/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0245\n",
            "Epoch 380/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 1s - 64ms/step - loss: 0.0246\n",
            "Epoch 381/1000\n",
            "8/8 - 0s - 47ms/step - loss: 0.0245\n",
            "Epoch 382/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0244\n",
            "Epoch 383/1000\n",
            "8/8 - 0s - 47ms/step - loss: 0.0242\n",
            "Epoch 384/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0243\n",
            "Epoch 385/1000\n",
            "8/8 - 0s - 47ms/step - loss: 0.0243\n",
            "Epoch 386/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0240\n",
            "Epoch 387/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0239\n",
            "Epoch 388/1000\n",
            "8/8 - 0s - 47ms/step - loss: 0.0240\n",
            "Epoch 389/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0238\n",
            "Epoch 390/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 1s - 68ms/step - loss: 0.0237\n",
            "Epoch 391/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0234\n",
            "Epoch 392/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0235\n",
            "Epoch 393/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0236\n",
            "Epoch 394/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0233\n",
            "Epoch 395/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0234\n",
            "Epoch 396/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0233\n",
            "Epoch 397/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0230\n",
            "Epoch 398/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0233\n",
            "Epoch 399/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0229\n",
            "Epoch 400/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 1s - 63ms/step - loss: 0.0233\n",
            "Epoch 401/1000\n",
            "8/8 - 0s - 47ms/step - loss: 0.0233\n",
            "Epoch 402/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0232\n",
            "Epoch 403/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0229\n",
            "Epoch 404/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0228\n",
            "Epoch 405/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0230\n",
            "Epoch 406/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0229\n",
            "Epoch 407/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0225\n",
            "Epoch 408/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0226\n",
            "Epoch 409/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0235\n",
            "Epoch 410/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 1s - 63ms/step - loss: 0.0229\n",
            "Epoch 411/1000\n",
            "8/8 - 0s - 47ms/step - loss: 0.0226\n",
            "Epoch 412/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0230\n",
            "Epoch 413/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0223\n",
            "Epoch 414/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0224\n",
            "Epoch 415/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0224\n",
            "Epoch 416/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0222\n",
            "Epoch 417/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0222\n",
            "Epoch 418/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0221\n",
            "Epoch 419/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0223\n",
            "Epoch 420/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 1s - 68ms/step - loss: 0.0220\n",
            "Epoch 421/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0218\n",
            "Epoch 422/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0220\n",
            "Epoch 423/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0219\n",
            "Epoch 424/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0218\n",
            "Epoch 425/1000\n",
            "8/8 - 0s - 47ms/step - loss: 0.0220\n",
            "Epoch 426/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0217\n",
            "Epoch 427/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0216\n",
            "Epoch 428/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0222\n",
            "Epoch 429/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0215\n",
            "Epoch 430/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 0s - 61ms/step - loss: 0.0215\n",
            "Epoch 431/1000\n",
            "8/8 - 0s - 46ms/step - loss: 0.0213\n",
            "Epoch 432/1000\n",
            "8/8 - 0s - 47ms/step - loss: 0.0213\n",
            "Epoch 433/1000\n",
            "8/8 - 0s - 47ms/step - loss: 0.0216\n",
            "Epoch 434/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0221\n",
            "Epoch 435/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0216\n",
            "Epoch 436/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0215\n",
            "Epoch 437/1000\n",
            "8/8 - 0s - 47ms/step - loss: 0.0215\n",
            "Epoch 438/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0213\n",
            "Epoch 439/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0214\n",
            "Epoch 440/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 1s - 64ms/step - loss: 0.0212\n",
            "Epoch 441/1000\n",
            "8/8 - 0s - 46ms/step - loss: 0.0211\n",
            "Epoch 442/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0210\n",
            "Epoch 443/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0212\n",
            "Epoch 444/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0206\n",
            "Epoch 445/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0211\n",
            "Epoch 446/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0208\n",
            "Epoch 447/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0210\n",
            "Epoch 448/1000\n",
            "8/8 - 0s - 47ms/step - loss: 0.0207\n",
            "Epoch 449/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0205\n",
            "Epoch 450/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 1s - 69ms/step - loss: 0.0206\n",
            "Epoch 451/1000\n",
            "8/8 - 0s - 46ms/step - loss: 0.0207\n",
            "Epoch 452/1000\n",
            "8/8 - 0s - 47ms/step - loss: 0.0206\n",
            "Epoch 453/1000\n",
            "8/8 - 0s - 47ms/step - loss: 0.0211\n",
            "Epoch 454/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0208\n",
            "Epoch 455/1000\n",
            "8/8 - 0s - 47ms/step - loss: 0.0207\n",
            "Epoch 456/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0205\n",
            "Epoch 457/1000\n",
            "8/8 - 0s - 47ms/step - loss: 0.0206\n",
            "Epoch 458/1000\n",
            "8/8 - 0s - 47ms/step - loss: 0.0206\n",
            "Epoch 459/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0205\n",
            "Epoch 460/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 0s - 62ms/step - loss: 0.0205\n",
            "Epoch 461/1000\n",
            "8/8 - 0s - 47ms/step - loss: 0.0206\n",
            "Epoch 462/1000\n",
            "8/8 - 0s - 47ms/step - loss: 0.0204\n",
            "Epoch 463/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0202\n",
            "Epoch 464/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0201\n",
            "Epoch 465/1000\n",
            "8/8 - 0s - 47ms/step - loss: 0.0202\n",
            "Epoch 466/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0201\n",
            "Epoch 467/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0200\n",
            "Epoch 468/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0201\n",
            "Epoch 469/1000\n",
            "8/8 - 0s - 47ms/step - loss: 0.0202\n",
            "Epoch 470/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 1s - 63ms/step - loss: 0.0201\n",
            "Epoch 471/1000\n",
            "8/8 - 0s - 47ms/step - loss: 0.0197\n",
            "Epoch 472/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0200\n",
            "Epoch 473/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0197\n",
            "Epoch 474/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0201\n",
            "Epoch 475/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0202\n",
            "Epoch 476/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0200\n",
            "Epoch 477/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0200\n",
            "Epoch 478/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0201\n",
            "Epoch 479/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0200\n",
            "Epoch 480/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 0s - 62ms/step - loss: 0.0198\n",
            "Epoch 481/1000\n",
            "8/8 - 0s - 47ms/step - loss: 0.0197\n",
            "Epoch 482/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0197\n",
            "Epoch 483/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0196\n",
            "Epoch 484/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0198\n",
            "Epoch 485/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0197\n",
            "Epoch 486/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0197\n",
            "Epoch 487/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0200\n",
            "Epoch 488/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0198\n",
            "Epoch 489/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0197\n",
            "Epoch 490/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 1s - 63ms/step - loss: 0.0195\n",
            "Epoch 491/1000\n",
            "8/8 - 0s - 47ms/step - loss: 0.0196\n",
            "Epoch 492/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0193\n",
            "Epoch 493/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0192\n",
            "Epoch 494/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0194\n",
            "Epoch 495/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0193\n",
            "Epoch 496/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0194\n",
            "Epoch 497/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0193\n",
            "Epoch 498/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0196\n",
            "Epoch 499/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0190\n",
            "Epoch 500/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 1s - 63ms/step - loss: 0.0190\n",
            "Epoch 501/1000\n",
            "8/8 - 0s - 47ms/step - loss: 0.0191\n",
            "Epoch 502/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0190\n",
            "Epoch 503/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0190\n",
            "Epoch 504/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0190\n",
            "Epoch 505/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0191\n",
            "Epoch 506/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0190\n",
            "Epoch 507/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0189\n",
            "Epoch 508/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0188\n",
            "Epoch 509/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0187\n",
            "Epoch 510/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 1s - 63ms/step - loss: 0.0188\n",
            "Epoch 511/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0186\n",
            "Epoch 512/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0188\n",
            "Epoch 513/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0189\n",
            "Epoch 514/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0189\n",
            "Epoch 515/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0190\n",
            "Epoch 516/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0188\n",
            "Epoch 517/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0188\n",
            "Epoch 518/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0186\n",
            "Epoch 519/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0187\n",
            "Epoch 520/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 0s - 62ms/step - loss: 0.0185\n",
            "Epoch 521/1000\n",
            "8/8 - 0s - 47ms/step - loss: 0.0184\n",
            "Epoch 522/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0183\n",
            "Epoch 523/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0184\n",
            "Epoch 524/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0195\n",
            "Epoch 525/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0194\n",
            "Epoch 526/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0188\n",
            "Epoch 527/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0187\n",
            "Epoch 528/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0188\n",
            "Epoch 529/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0188\n",
            "Epoch 530/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 1s - 63ms/step - loss: 0.0193\n",
            "Epoch 531/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0203\n",
            "Epoch 532/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0206\n",
            "Epoch 533/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0209\n",
            "Epoch 534/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0223\n",
            "Epoch 535/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0250\n",
            "Epoch 536/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0254\n",
            "Epoch 537/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0254\n",
            "Epoch 538/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0325\n",
            "Epoch 539/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0329\n",
            "Epoch 540/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 1s - 65ms/step - loss: 0.0418\n",
            "Epoch 541/1000\n",
            "8/8 - 0s - 47ms/step - loss: 0.0379\n",
            "Epoch 542/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0350\n",
            "Epoch 543/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0279\n",
            "Epoch 544/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0278\n",
            "Epoch 545/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0250\n",
            "Epoch 546/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0227\n",
            "Epoch 547/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0216\n",
            "Epoch 548/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0208\n",
            "Epoch 549/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0204\n",
            "Epoch 550/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 1s - 65ms/step - loss: 0.0198\n",
            "Epoch 551/1000\n",
            "8/8 - 0s - 47ms/step - loss: 0.0195\n",
            "Epoch 552/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0188\n",
            "Epoch 553/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0189\n",
            "Epoch 554/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0184\n",
            "Epoch 555/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0182\n",
            "Epoch 556/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0184\n",
            "Epoch 557/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0182\n",
            "Epoch 558/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0182\n",
            "Epoch 559/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0180\n",
            "Epoch 560/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 1s - 63ms/step - loss: 0.0180\n",
            "Epoch 561/1000\n",
            "8/8 - 0s - 47ms/step - loss: 0.0179\n",
            "Epoch 562/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0182\n",
            "Epoch 563/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0178\n",
            "Epoch 564/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0180\n",
            "Epoch 565/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0177\n",
            "Epoch 566/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0178\n",
            "Epoch 567/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0175\n",
            "Epoch 568/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0177\n",
            "Epoch 569/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0179\n",
            "Epoch 570/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 1s - 64ms/step - loss: 0.0178\n",
            "Epoch 571/1000\n",
            "8/8 - 0s - 47ms/step - loss: 0.0184\n",
            "Epoch 572/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0179\n",
            "Epoch 573/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0174\n",
            "Epoch 574/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0176\n",
            "Epoch 575/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0174\n",
            "Epoch 576/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0171\n",
            "Epoch 577/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0173\n",
            "Epoch 578/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0175\n",
            "Epoch 579/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0172\n",
            "Epoch 580/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 0s - 62ms/step - loss: 0.0174\n",
            "Epoch 581/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0174\n",
            "Epoch 582/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0173\n",
            "Epoch 583/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0173\n",
            "Epoch 584/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0170\n",
            "Epoch 585/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0170\n",
            "Epoch 586/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0172\n",
            "Epoch 587/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0169\n",
            "Epoch 588/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0170\n",
            "Epoch 589/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0172\n",
            "Epoch 590/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 1s - 70ms/step - loss: 0.0171\n",
            "Epoch 591/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0172\n",
            "Epoch 592/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0169\n",
            "Epoch 593/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0170\n",
            "Epoch 594/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0170\n",
            "Epoch 595/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0169\n",
            "Epoch 596/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0170\n",
            "Epoch 597/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0169\n",
            "Epoch 598/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0166\n",
            "Epoch 599/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0170\n",
            "Epoch 600/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 1s - 63ms/step - loss: 0.0168\n",
            "Epoch 601/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0169\n",
            "Epoch 602/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0168\n",
            "Epoch 603/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0168\n",
            "Epoch 604/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0167\n",
            "Epoch 605/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0168\n",
            "Epoch 606/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0166\n",
            "Epoch 607/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0167\n",
            "Epoch 608/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0167\n",
            "Epoch 609/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0167\n",
            "Epoch 610/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 1s - 64ms/step - loss: 0.0167\n",
            "Epoch 611/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0169\n",
            "Epoch 612/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0166\n",
            "Epoch 613/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0164\n",
            "Epoch 614/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0166\n",
            "Epoch 615/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0164\n",
            "Epoch 616/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0166\n",
            "Epoch 617/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0164\n",
            "Epoch 618/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0166\n",
            "Epoch 619/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0164\n",
            "Epoch 620/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 1s - 67ms/step - loss: 0.0167\n",
            "Epoch 621/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0166\n",
            "Epoch 622/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0166\n",
            "Epoch 623/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0168\n",
            "Epoch 624/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0165\n",
            "Epoch 625/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0163\n",
            "Epoch 626/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0163\n",
            "Epoch 627/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0166\n",
            "Epoch 628/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0163\n",
            "Epoch 629/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0164\n",
            "Epoch 630/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 1s - 64ms/step - loss: 0.0165\n",
            "Epoch 631/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0168\n",
            "Epoch 632/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0162\n",
            "Epoch 633/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0162\n",
            "Epoch 634/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0161\n",
            "Epoch 635/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0160\n",
            "Epoch 636/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0162\n",
            "Epoch 637/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0162\n",
            "Epoch 638/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0161\n",
            "Epoch 639/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0160\n",
            "Epoch 640/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful printed soft \n",
            "\n",
            "8/8 - 1s - 64ms/step - loss: 0.0162\n",
            "Epoch 641/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0162\n",
            "Epoch 642/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0160\n",
            "Epoch 643/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0164\n",
            "Epoch 644/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0161\n",
            "Epoch 645/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0163\n",
            "Epoch 646/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0162\n",
            "Epoch 647/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0160\n",
            "Epoch 648/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0159\n",
            "Epoch 649/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0159\n",
            "Epoch 650/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 1s - 64ms/step - loss: 0.0158\n",
            "Epoch 651/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0157\n",
            "Epoch 652/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0159\n",
            "Epoch 653/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0156\n",
            "Epoch 654/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0157\n",
            "Epoch 655/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0159\n",
            "Epoch 656/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0158\n",
            "Epoch 657/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0159\n",
            "Epoch 658/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0160\n",
            "Epoch 659/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0159\n",
            "Epoch 660/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 1s - 65ms/step - loss: 0.0159\n",
            "Epoch 661/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0160\n",
            "Epoch 662/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0159\n",
            "Epoch 663/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0159\n",
            "Epoch 664/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0159\n",
            "Epoch 665/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0158\n",
            "Epoch 666/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0159\n",
            "Epoch 667/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0155\n",
            "Epoch 668/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0157\n",
            "Epoch 669/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0157\n",
            "Epoch 670/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 1s - 65ms/step - loss: 0.0154\n",
            "Epoch 671/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0157\n",
            "Epoch 672/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0158\n",
            "Epoch 673/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0157\n",
            "Epoch 674/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0160\n",
            "Epoch 675/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0156\n",
            "Epoch 676/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0157\n",
            "Epoch 677/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0153\n",
            "Epoch 678/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0154\n",
            "Epoch 679/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0156\n",
            "Epoch 680/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 1s - 63ms/step - loss: 0.0155\n",
            "Epoch 681/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0155\n",
            "Epoch 682/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0155\n",
            "Epoch 683/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0157\n",
            "Epoch 684/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0156\n",
            "Epoch 685/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0157\n",
            "Epoch 686/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0153\n",
            "Epoch 687/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0155\n",
            "Epoch 688/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0156\n",
            "Epoch 689/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0157\n",
            "Epoch 690/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 1s - 64ms/step - loss: 0.0156\n",
            "Epoch 691/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0158\n",
            "Epoch 692/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0154\n",
            "Epoch 693/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0151\n",
            "Epoch 694/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0154\n",
            "Epoch 695/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0154\n",
            "Epoch 696/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0155\n",
            "Epoch 697/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0152\n",
            "Epoch 698/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0151\n",
            "Epoch 699/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0155\n",
            "Epoch 700/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 1s - 73ms/step - loss: 0.0152\n",
            "Epoch 701/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0152\n",
            "Epoch 702/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0155\n",
            "Epoch 703/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0152\n",
            "Epoch 704/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0157\n",
            "Epoch 705/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0156\n",
            "Epoch 706/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0153\n",
            "Epoch 707/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0152\n",
            "Epoch 708/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0150\n",
            "Epoch 709/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0153\n",
            "Epoch 710/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 1s - 65ms/step - loss: 0.0154\n",
            "Epoch 711/1000\n",
            "8/8 - 0s - 48ms/step - loss: 0.0154\n",
            "Epoch 712/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0152\n",
            "Epoch 713/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0152\n",
            "Epoch 714/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0149\n",
            "Epoch 715/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0151\n",
            "Epoch 716/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0151\n",
            "Epoch 717/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0150\n",
            "Epoch 718/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0150\n",
            "Epoch 719/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0151\n",
            "Epoch 720/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 1s - 67ms/step - loss: 0.0152\n",
            "Epoch 721/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0150\n",
            "Epoch 722/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0150\n",
            "Epoch 723/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0148\n",
            "Epoch 724/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0149\n",
            "Epoch 725/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0153\n",
            "Epoch 726/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0153\n",
            "Epoch 727/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0152\n",
            "Epoch 728/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0150\n",
            "Epoch 729/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0149\n",
            "Epoch 730/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 1s - 73ms/step - loss: 0.0151\n",
            "Epoch 731/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0149\n",
            "Epoch 732/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0149\n",
            "Epoch 733/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0149\n",
            "Epoch 734/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0149\n",
            "Epoch 735/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0148\n",
            "Epoch 736/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0151\n",
            "Epoch 737/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0150\n",
            "Epoch 738/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0150\n",
            "Epoch 739/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0149\n",
            "Epoch 740/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 1s - 66ms/step - loss: 0.0148\n",
            "Epoch 741/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0149\n",
            "Epoch 742/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0150\n",
            "Epoch 743/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0149\n",
            "Epoch 744/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0150\n",
            "Epoch 745/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0149\n",
            "Epoch 746/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0149\n",
            "Epoch 747/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0146\n",
            "Epoch 748/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0147\n",
            "Epoch 749/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0149\n",
            "Epoch 750/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 1s - 64ms/step - loss: 0.0151\n",
            "Epoch 751/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0148\n",
            "Epoch 752/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0148\n",
            "Epoch 753/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0148\n",
            "Epoch 754/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0147\n",
            "Epoch 755/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0149\n",
            "Epoch 756/1000\n",
            "8/8 - 0s - 51ms/step - loss: 0.0146\n",
            "Epoch 757/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0145\n",
            "Epoch 758/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0150\n",
            "Epoch 759/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0147\n",
            "Epoch 760/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 1s - 65ms/step - loss: 0.0149\n",
            "Epoch 761/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0145\n",
            "Epoch 762/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0147\n",
            "Epoch 763/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0148\n",
            "Epoch 764/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0146\n",
            "Epoch 765/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0148\n",
            "Epoch 766/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0147\n",
            "Epoch 767/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0146\n",
            "Epoch 768/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0149\n",
            "Epoch 769/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0147\n",
            "Epoch 770/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 1s - 65ms/step - loss: 0.0146\n",
            "Epoch 771/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0146\n",
            "Epoch 772/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0147\n",
            "Epoch 773/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0146\n",
            "Epoch 774/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0145\n",
            "Epoch 775/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0147\n",
            "Epoch 776/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0146\n",
            "Epoch 777/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0145\n",
            "Epoch 778/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0147\n",
            "Epoch 779/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0147\n",
            "Epoch 780/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 1s - 64ms/step - loss: 0.0145\n",
            "Epoch 781/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0147\n",
            "Epoch 782/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0147\n",
            "Epoch 783/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0145\n",
            "Epoch 784/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0147\n",
            "Epoch 785/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0143\n",
            "Epoch 786/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0145\n",
            "Epoch 787/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0144\n",
            "Epoch 788/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0147\n",
            "Epoch 789/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0146\n",
            "Epoch 790/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 1s - 65ms/step - loss: 0.0146\n",
            "Epoch 791/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0146\n",
            "Epoch 792/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0147\n",
            "Epoch 793/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0145\n",
            "Epoch 794/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0147\n",
            "Epoch 795/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0148\n",
            "Epoch 796/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0146\n",
            "Epoch 797/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0150\n",
            "Epoch 798/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0146\n",
            "Epoch 799/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0144\n",
            "Epoch 800/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 1s - 65ms/step - loss: 0.0144\n",
            "Epoch 801/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0145\n",
            "Epoch 802/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0146\n",
            "Epoch 803/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0143\n",
            "Epoch 804/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0143\n",
            "Epoch 805/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0146\n",
            "Epoch 806/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0150\n",
            "Epoch 807/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0148\n",
            "Epoch 808/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0145\n",
            "Epoch 809/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0143\n",
            "Epoch 810/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 1s - 69ms/step - loss: 0.0143\n",
            "Epoch 811/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0148\n",
            "Epoch 812/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0148\n",
            "Epoch 813/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0146\n",
            "Epoch 814/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0147\n",
            "Epoch 815/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0149\n",
            "Epoch 816/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0146\n",
            "Epoch 817/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0144\n",
            "Epoch 818/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0155\n",
            "Epoch 819/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0152\n",
            "Epoch 820/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 1s - 64ms/step - loss: 0.0161\n",
            "Epoch 821/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0169\n",
            "Epoch 822/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0161\n",
            "Epoch 823/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0154\n",
            "Epoch 824/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0157\n",
            "Epoch 825/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0154\n",
            "Epoch 826/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0153\n",
            "Epoch 827/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0151\n",
            "Epoch 828/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0146\n",
            "Epoch 829/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0149\n",
            "Epoch 830/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 1s - 66ms/step - loss: 0.0150\n",
            "Epoch 831/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0156\n",
            "Epoch 832/1000\n",
            "8/8 - 0s - 51ms/step - loss: 0.0147\n",
            "Epoch 833/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0150\n",
            "Epoch 834/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0149\n",
            "Epoch 835/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0147\n",
            "Epoch 836/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0147\n",
            "Epoch 837/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0146\n",
            "Epoch 838/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0148\n",
            "Epoch 839/1000\n",
            "8/8 - 0s - 51ms/step - loss: 0.0146\n",
            "Epoch 840/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 1s - 69ms/step - loss: 0.0144\n",
            "Epoch 841/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0142\n",
            "Epoch 842/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0148\n",
            "Epoch 843/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0150\n",
            "Epoch 844/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0147\n",
            "Epoch 845/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0143\n",
            "Epoch 846/1000\n",
            "8/8 - 0s - 51ms/step - loss: 0.0146\n",
            "Epoch 847/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0144\n",
            "Epoch 848/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0144\n",
            "Epoch 849/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0145\n",
            "Epoch 850/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 1s - 64ms/step - loss: 0.0145\n",
            "Epoch 851/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0142\n",
            "Epoch 852/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0142\n",
            "Epoch 853/1000\n",
            "8/8 - 0s - 51ms/step - loss: 0.0144\n",
            "Epoch 854/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0142\n",
            "Epoch 855/1000\n",
            "8/8 - 0s - 51ms/step - loss: 0.0145\n",
            "Epoch 856/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0144\n",
            "Epoch 857/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0143\n",
            "Epoch 858/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0143\n",
            "Epoch 859/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0144\n",
            "Epoch 860/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 1s - 66ms/step - loss: 0.0142\n",
            "Epoch 861/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0137\n",
            "Epoch 862/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0142\n",
            "Epoch 863/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0142\n",
            "Epoch 864/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0140\n",
            "Epoch 865/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0140\n",
            "Epoch 866/1000\n",
            "8/8 - 0s - 51ms/step - loss: 0.0140\n",
            "Epoch 867/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0142\n",
            "Epoch 868/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0143\n",
            "Epoch 869/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0142\n",
            "Epoch 870/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 1s - 65ms/step - loss: 0.0141\n",
            "Epoch 871/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0140\n",
            "Epoch 872/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0144\n",
            "Epoch 873/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0143\n",
            "Epoch 874/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0142\n",
            "Epoch 875/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0142\n",
            "Epoch 876/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0142\n",
            "Epoch 877/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0144\n",
            "Epoch 878/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0143\n",
            "Epoch 879/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0143\n",
            "Epoch 880/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 1s - 66ms/step - loss: 0.0138\n",
            "Epoch 881/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0140\n",
            "Epoch 882/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0142\n",
            "Epoch 883/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0140\n",
            "Epoch 884/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0143\n",
            "Epoch 885/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0140\n",
            "Epoch 886/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0142\n",
            "Epoch 887/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0139\n",
            "Epoch 888/1000\n",
            "8/8 - 0s - 51ms/step - loss: 0.0140\n",
            "Epoch 889/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0142\n",
            "Epoch 890/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 1s - 66ms/step - loss: 0.0140\n",
            "Epoch 891/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0139\n",
            "Epoch 892/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0139\n",
            "Epoch 893/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0140\n",
            "Epoch 894/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0142\n",
            "Epoch 895/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0141\n",
            "Epoch 896/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0141\n",
            "Epoch 897/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0139\n",
            "Epoch 898/1000\n",
            "8/8 - 0s - 51ms/step - loss: 0.0139\n",
            "Epoch 899/1000\n",
            "8/8 - 0s - 51ms/step - loss: 0.0140\n",
            "Epoch 900/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 1s - 64ms/step - loss: 0.0139\n",
            "Epoch 901/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0137\n",
            "Epoch 902/1000\n",
            "8/8 - 0s - 51ms/step - loss: 0.0141\n",
            "Epoch 903/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0141\n",
            "Epoch 904/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0139\n",
            "Epoch 905/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0141\n",
            "Epoch 906/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0139\n",
            "Epoch 907/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0140\n",
            "Epoch 908/1000\n",
            "8/8 - 0s - 51ms/step - loss: 0.0141\n",
            "Epoch 909/1000\n",
            "8/8 - 0s - 51ms/step - loss: 0.0139\n",
            "Epoch 910/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 1s - 64ms/step - loss: 0.0139\n",
            "Epoch 911/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0142\n",
            "Epoch 912/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0140\n",
            "Epoch 913/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0140\n",
            "Epoch 914/1000\n",
            "8/8 - 0s - 51ms/step - loss: 0.0136\n",
            "Epoch 915/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0141\n",
            "Epoch 916/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0139\n",
            "Epoch 917/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0139\n",
            "Epoch 918/1000\n",
            "8/8 - 0s - 51ms/step - loss: 0.0140\n",
            "Epoch 919/1000\n",
            "8/8 - 0s - 51ms/step - loss: 0.0144\n",
            "Epoch 920/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 1s - 70ms/step - loss: 0.0141\n",
            "Epoch 921/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0142\n",
            "Epoch 922/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0140\n",
            "Epoch 923/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0138\n",
            "Epoch 924/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0138\n",
            "Epoch 925/1000\n",
            "8/8 - 0s - 51ms/step - loss: 0.0140\n",
            "Epoch 926/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0138\n",
            "Epoch 927/1000\n",
            "8/8 - 0s - 51ms/step - loss: 0.0141\n",
            "Epoch 928/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0141\n",
            "Epoch 929/1000\n",
            "8/8 - 0s - 51ms/step - loss: 0.0137\n",
            "Epoch 930/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 1s - 66ms/step - loss: 0.0138\n",
            "Epoch 931/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0137\n",
            "Epoch 932/1000\n",
            "8/8 - 0s - 51ms/step - loss: 0.0137\n",
            "Epoch 933/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0141\n",
            "Epoch 934/1000\n",
            "8/8 - 0s - 51ms/step - loss: 0.0136\n",
            "Epoch 935/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0135\n",
            "Epoch 936/1000\n",
            "8/8 - 0s - 51ms/step - loss: 0.0139\n",
            "Epoch 937/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0143\n",
            "Epoch 938/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0143\n",
            "Epoch 939/1000\n",
            "8/8 - 0s - 51ms/step - loss: 0.0139\n",
            "Epoch 940/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 1s - 66ms/step - loss: 0.0139\n",
            "Epoch 941/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0137\n",
            "Epoch 942/1000\n",
            "8/8 - 0s - 51ms/step - loss: 0.0137\n",
            "Epoch 943/1000\n",
            "8/8 - 0s - 51ms/step - loss: 0.0137\n",
            "Epoch 944/1000\n",
            "8/8 - 0s - 51ms/step - loss: 0.0136\n",
            "Epoch 945/1000\n",
            "8/8 - 0s - 51ms/step - loss: 0.0135\n",
            "Epoch 946/1000\n",
            "8/8 - 0s - 51ms/step - loss: 0.0138\n",
            "Epoch 947/1000\n",
            "8/8 - 0s - 51ms/step - loss: 0.0135\n",
            "Epoch 948/1000\n",
            "8/8 - 0s - 51ms/step - loss: 0.0136\n",
            "Epoch 949/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0139\n",
            "Epoch 950/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 1s - 67ms/step - loss: 0.0137\n",
            "Epoch 951/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0134\n",
            "Epoch 952/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0138\n",
            "Epoch 953/1000\n",
            "8/8 - 0s - 51ms/step - loss: 0.0137\n",
            "Epoch 954/1000\n",
            "8/8 - 0s - 51ms/step - loss: 0.0138\n",
            "Epoch 955/1000\n",
            "8/8 - 0s - 51ms/step - loss: 0.0140\n",
            "Epoch 956/1000\n",
            "8/8 - 0s - 51ms/step - loss: 0.0142\n",
            "Epoch 957/1000\n",
            "8/8 - 0s - 51ms/step - loss: 0.0138\n",
            "Epoch 958/1000\n",
            "8/8 - 0s - 51ms/step - loss: 0.0136\n",
            "Epoch 959/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0136\n",
            "Epoch 960/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 1s - 66ms/step - loss: 0.0137\n",
            "Epoch 961/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0138\n",
            "Epoch 962/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0139\n",
            "Epoch 963/1000\n",
            "8/8 - 0s - 51ms/step - loss: 0.0136\n",
            "Epoch 964/1000\n",
            "8/8 - 0s - 51ms/step - loss: 0.0135\n",
            "Epoch 965/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0137\n",
            "Epoch 966/1000\n",
            "8/8 - 0s - 51ms/step - loss: 0.0139\n",
            "Epoch 967/1000\n",
            "8/8 - 0s - 51ms/step - loss: 0.0139\n",
            "Epoch 968/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0141\n",
            "Epoch 969/1000\n",
            "8/8 - 0s - 51ms/step - loss: 0.0137\n",
            "Epoch 970/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 1s - 65ms/step - loss: 0.0134\n",
            "Epoch 971/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0137\n",
            "Epoch 972/1000\n",
            "8/8 - 0s - 51ms/step - loss: 0.0136\n",
            "Epoch 973/1000\n",
            "8/8 - 0s - 51ms/step - loss: 0.0137\n",
            "Epoch 974/1000\n",
            "8/8 - 0s - 51ms/step - loss: 0.0137\n",
            "Epoch 975/1000\n",
            "8/8 - 0s - 51ms/step - loss: 0.0137\n",
            "Epoch 976/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0135\n",
            "Epoch 977/1000\n",
            "8/8 - 0s - 51ms/step - loss: 0.0136\n",
            "Epoch 978/1000\n",
            "8/8 - 0s - 51ms/step - loss: 0.0135\n",
            "Epoch 979/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0135\n",
            "Epoch 980/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 1s - 66ms/step - loss: 0.0135\n",
            "Epoch 981/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0136\n",
            "Epoch 982/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0135\n",
            "Epoch 983/1000\n",
            "8/8 - 0s - 51ms/step - loss: 0.0136\n",
            "Epoch 984/1000\n",
            "8/8 - 0s - 51ms/step - loss: 0.0135\n",
            "Epoch 985/1000\n",
            "8/8 - 0s - 51ms/step - loss: 0.0136\n",
            "Epoch 986/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0134\n",
            "Epoch 987/1000\n",
            "8/8 - 0s - 51ms/step - loss: 0.0137\n",
            "Epoch 988/1000\n",
            "8/8 - 0s - 51ms/step - loss: 0.0136\n",
            "Epoch 989/1000\n",
            "8/8 - 0s - 51ms/step - loss: 0.0135\n",
            "Epoch 990/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 1s - 66ms/step - loss: 0.0136\n",
            "Epoch 991/1000\n",
            "8/8 - 0s - 49ms/step - loss: 0.0135\n",
            "Epoch 992/1000\n",
            "8/8 - 0s - 51ms/step - loss: 0.0133\n",
            "Epoch 993/1000\n",
            "8/8 - 0s - 51ms/step - loss: 0.0135\n",
            "Epoch 994/1000\n",
            "8/8 - 0s - 51ms/step - loss: 0.0135\n",
            "Epoch 995/1000\n",
            "8/8 - 0s - 51ms/step - loss: 0.0138\n",
            "Epoch 996/1000\n",
            "8/8 - 0s - 51ms/step - loss: 0.0135\n",
            "Epoch 997/1000\n",
            "8/8 - 0s - 50ms/step - loss: 0.0135\n",
            "Epoch 998/1000\n",
            "8/8 - 0s - 51ms/step - loss: 0.0135\n",
            "Epoch 999/1000\n",
            "8/8 - 0s - 51ms/step - loss: 0.0140\n",
            "Epoch 1000/1000\n",
            "Generated text:\n",
            " Abeni, a bright-eyed girl with braids adorned with colorful beads, lived \n",
            "\n",
            "8/8 - 1s - 73ms/step - loss: 0.0134\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 1000  # @param {type: \"number\"}\n",
        "# verbose=2: Instructs the model.fit method to print one line per\n",
        "# epoch so you see how the loss is decreasing and generated texts improving.\n",
        "history = model.fit(\n",
        "    x=batches, verbose=2, epochs=num_epochs, callbacks=[text_gen_callback]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zf1BR0cGoy0V"
      },
      "source": [
        "While the model is training, you can observe how the generated text changes. At the beginning of the training, the generation will likely be a random collection of words. By the end of the training, however, the generation should start to become more coherent.\n",
        "\n",
        "Apart from observing how the generated text changes, you can also check how the **loss** changes as training progresses. If the model is training properly, the loss should go down as training continues. You may find that the loss temporarily goes up again from one epoch to another. This is nothing to worry about, but the general trend should be that the loss descreases.\n",
        "\n",
        "Once the training process has finished (this can take some time), you can prompt the model as you did in earlier labs.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTbezoZr5VKc"
      },
      "source": [
        "#### Evaluate your small language model\n",
        "\n",
        "After training a model, researchers have to perform many evaluations to determine whether it is performing well in many scenarios.\n",
        "\n",
        "As a final activity, you will also evaluate your model. The remainder of this lab guides you through this evaluation process. You will ask the following key questions to evaluate your model's quality:\n",
        "\n",
        "*   A. How good is your model at predicting the next token for a given prompt based on patterns identified in the training dataset?\n",
        "*   B. Is the generated text coherent, and does it make sense given the context?\n",
        "*   C. Is the likely next token what you expect to see when the context is changed slightly?\n",
        "\n",
        "When evaluating your model, you may find it useful to take some notes. To do this, you can either add cells to this Colab notebook or take notes on [Google Docs](https://docs.google.com/), [Notebook LM](https://notebooklm.google/), a piece of paper, or any other note-taking tool of your choice."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukARAmZpEUOJ"
      },
      "source": [
        "### How good is your model at predicting the next token for a given prompt based on patterns identified in the training dataset?\n",
        "\n",
        "The following steps provide you with some guidance on how to answer this question.\n",
        "\n",
        "* Prompt the model using a token or sequence of tokens from the training dataset. For example, you can start with `\"Abeni, a bright-eyed\"`.\n",
        "* Visualize the probability distribution of the next token for a given prompt.\n",
        "* Increase `num_tokens_to_generate` to generate longer texts.\n",
        "* Inspect the generated text. See how well the model has learned to generate text that reflects the patterns learned during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "5E06Mp-wFC8q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "outputId": "9f1d0d3e-bc20-4231-8d18-78af54574e19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated text: Abeni, a bright-eyed girl with braids adorned with colorful beads, lived in a small village nestled beside a sparkling river. The air often hummed with the rhythmic pounding of mortars and pestles as women prepared the evening meal. But no aroma was as enticing to Abeni as the rich, smoky fragrance of Jollof Rice,\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"9741d1c2-84a4-4c4a-b4a5-a70210228472\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"9741d1c2-84a4-4c4a-b4a5-a70210228472\")) {                    Plotly.newPlot(                        \"9741d1c2-84a4-4c4a-b4a5-a70210228472\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"x=%{x}\\u003cbr\\u003ey=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"textposition\":\"auto\",\"x\":[\"'girl'\",\"'she'\",\"'popular'\",\"'bright-eyed'\",\"'bite'\",\"'creamy,'\",\"'stews'\",\"'Would'\",\"'day'\",\"'warming'\",\"'koeksister'\",\"'omelette'\",\"'eyes'\",\"'classic'\",\"'rice'\",\"'bright'\",\"'made'\",\"'spongy,'\",\"'slow-cooked'\",\"'mischievous'\",\"'beloved'\",\"'sculpture,'\",\"'Ethiopian'\",\"'Their'\",\"'usually'\",\"'colorful'\",\"'survive'\",\"'The'\",\"'favorite'\",\"'beverage'\"],\"xaxis\":\"x\",\"y\":[0.99965143,0.000026399453,0.00002263494,0.000007825342,0.0000060900315,0.0000057904476,0.0000055076807,0.000005365533,0.00000534996,0.000004669514,0.000004590439,0.00000437246,0.000003866831,0.0000035365658,0.0000034202337,0.0000033291917,0.0000028421143,0.0000025325558,0.000002436534,0.0000023685122,0.0000023623988,0.0000022110673,0.0000021643473,0.0000018857546,0.0000017348646,0.0000016586857,0.0000015830686,0.0000015459751,0.0000015060177,0.0000014351649],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Tokens\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Probability\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\",\"title\":{\"text\":\"Probability distribution of next tokens given the prompt=\\\"Abeni, a bright-eyed\\\"\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('9741d1c2-84a4-4c4a-b4a5-a70210228472');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "prompt = \"Abeni, a bright-eyed\" #@param {type: \"string\"}\n",
        "num_tokens_to_generate = 51 #@param {type: \"number\"}\n",
        "generated_text, probs = generation.generate_text(\n",
        "    prompt,\n",
        "    num_tokens_to_generate,\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    pad_token_id=tokenizer.pad_token_id,\n",
        "    sampling_mode=\"greedy\" # To generate the highest probability generation.\n",
        ")\n",
        "\n",
        "print(\"Generated text:\", generated_text)\n",
        "print(\"\\n\")\n",
        "\n",
        "visualizations.plot_next_token(probs[0], prompt=prompt, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXz3Wu-10jlX"
      },
      "source": [
        "### Is the generated text coherent, and does it make sense given the context?\n",
        "* Prompt the model with a token  or a phrase of your choosing.\n",
        "* Increase `num_tokens_to_generate` to generate longer texts.\n",
        "* Visualize the probability distribution of the next token for a given prompt.\n",
        "* Inspect the quality of generated texts.\n",
        "\n",
        "Note that, above, the generation process always chooses the most probable next token from the set of candidate tokens. In the next cell, the generation process samples a next token according to the probability distribution predicted by the model. This is done by setting the `sampling_mode` parameter to `random`.\n",
        "\n",
        "------\n",
        "> **â„¹ï¸ Info: Unseen tokens**\n",
        ">\n",
        ">When you are trying different prompts, you may also notice that sometimes tokens get replaced by the special string `<UNK>`. This happens when you prompt the model with tokens that did not appear in the training dataset, so called **unseen tokens**. For these tokens, the `token_to_index` dictionary of the tokenizer does not have an entry and therefore they cannot be mapped to a token index.\n",
        ">\n",
        "> One method of dealing with such tokens is to add a special `<UNK>` token along with its index to the vocabulary of the tokenizer. Then, during **inference**, whenever there is an unseen token, it maps the token to the index of this special `<UNK>` token.\n",
        ">\n",
        "> This method is not ideal because all information in the token is lost. In later courses, you will learn more sophisticated methods of dealing with unseen tokens that do not rely on such a catch-all token. For now, you will likely observe that the model is not very good at predicting the next word if there are several unseen words in the prompt.\n",
        "------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "J1riRfT3lbA8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "outputId": "9b64057f-181b-435a-ee51-49a2f6314b4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated text: Jide was hungry so she went looking for Banku and tilapia, and soon she was enjoying the malsouka\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"d514b32d-72d1-4c33-9776-e1602e80fa03\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"d514b32d-72d1-4c33-9776-e1602e80fa03\")) {                    Plotly.newPlot(                        \"d514b32d-72d1-4c33-9776-e1602e80fa03\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"x=%{x}\\u003cbr\\u003ey=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"textposition\":\"auto\",\"x\":[\"'Banku'\",\"'sambusa,'\",\"'Maafe,'\",\"'a'\",\"'dodo,'\",\"'tilapia,'\",\"'Umqombothi,'\",\"'crispy'\",\"'Tella,'\",\"'perfection'\",\"'sugarcane'\",\"'slices'\",\"'boiled'\",\"'overall'\",\"'extra'\",\"'ginger,'\",\"'Nigeria,'\",\"'mitmita,'\",\"'one'\",\"'Doro'\",\"'promised'\",\"'become'\",\"'went'\",\"'injera'\",\"'strawberry'\",\"'cabbage,'\",\"'building'\",\"'Giza,'\",\"'sorghum'\",\"'celebrations'\"],\"xaxis\":\"x\",\"y\":[0.3336602,0.28918102,0.28653902,0.057669703,0.009847069,0.001993942,0.00083276344,0.00042204026,0.0004162102,0.00034021618,0.0002134247,0.00020593281,0.00020385542,0.00019177381,0.00018544252,0.00016983415,0.00016064018,0.00015701453,0.00014884073,0.00014871955,0.0001352271,0.00013365256,0.00013016563,0.00012842465,0.00012438431,0.0001153708,0.00011246831,0.00011211652,0.00010920572,0.00010881048],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Tokens\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Probability\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\",\"title\":{\"text\":\"Probability distribution of next tokens given the prompt=\\\"Jide was hungry so she went looking for\\\"\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('d514b32d-72d1-4c33-9776-e1602e80fa03');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "prompt = \"Jide was hungry so she went looking for\" #@param {type: \"string\"}\n",
        "num_tokens_to_generate = 10 #@param {type: \"number\"}\n",
        "generated_text, probs = generation.generate_text(\n",
        "    prompt,\n",
        "    num_tokens_to_generate,\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    pad_token_id=tokenizer.pad_token_id,\n",
        "    sampling_mode=\"random\",\n",
        ")\n",
        "print(\"Generated text:\", generated_text)\n",
        "print(\"\\n\")\n",
        "\n",
        "visualizations.plot_next_token(probs[0], prompt=prompt, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEoUkDVFd_0M"
      },
      "source": [
        "### Is the likely next token what you expect to see when the context is changed slightly?\n",
        "* Change the context of the prompt slightly.\n",
        "* Visualize the probability distribution of the next token for a given prompt.\n",
        "* Increase `num_tokens_to_generate` to generate longer texts.\n",
        "* Inspect the quality of generated texts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "hHFdQf4Fdn9x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "outputId": "cf02196d-da13-4c2e-9cc2-943a755fbe2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated text: Jide was thirsty so she went looking for sugarcane juice, and at a vibrant market stall, she found the fresh, naturally sweet beverage that quenched her thirst on a sweltering day. birdsong and was such as the was making Fufu, were the the central by the fastest bird on land. the diet lacking in essential nutrients or high in southwestern Africa. diet primarily mist and maritime trade and replenish found infused with the diet consists almost across southern\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"754247cc-8272-4a4d-820d-63c2890fba49\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"754247cc-8272-4a4d-820d-63c2890fba49\")) {                    Plotly.newPlot(                        \"754247cc-8272-4a4d-820d-63c2890fba49\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"x=%{x}\\u003cbr\\u003ey=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"textposition\":\"auto\",\"x\":[\"'sugarcane'\",\"'Umqombothi,'\",\"'Tella,'\",\"'malsouka'\",\"'anything.'\",\"\\\"that's\\\"\",\"'destination'\",\"'Congo,'\",\"'rehydration.'\",\"'Zambia,'\",\"'labels,'\",\"'savanna,'\",\"'warmly'\",\"'Tanzania,'\",\"'plateau'\",\"'dressed'\",\"'global'\",\"'tallest'\",\"'Eastern'\",\"'potassium,'\",\"'powerful'\",\"'cloth,'\",\"'vowels'\",\"'type'\",\"\\\"Zimbabwe's\\\"\",\"'dinosaur,'\",\"\\\"'king\\\"\",\"'Verde,'\",\"'learning,'\",\"'mangoes,'\"],\"xaxis\":\"x\",\"y\":[0.97862643,0.008715022,0.0008713281,0.00022635183,0.00012372459,0.00011682836,0.0001016748,0.00009982906,0.000097557735,0.00009597529,0.00009218962,0.00008883021,0.00008430592,0.00008226717,0.00007585785,0.00007337118,0.00006650087,0.000065593245,0.000064901986,0.000062375766,0.00005768628,0.000057276022,0.000056917626,0.00005647415,0.000054087934,0.00005296151,0.00005105119,0.000050863222,0.000049280185,0.000049073828],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Tokens\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Probability\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\",\"title\":{\"text\":\"Probability distribution of next tokens given the prompt=\\\"Jide was thirsty so she went looking for\\\"\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('754247cc-8272-4a4d-820d-63c2890fba49');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "prompt = \"Jide was thirsty so she went looking for\" #@param {type: \"string\"}\n",
        "num_tokens_to_generate = 70 #@param {type: \"number\"}\n",
        "generated_text, probs = generation.generate_text(\n",
        "    prompt,\n",
        "    num_tokens_to_generate,\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    pad_token_id=tokenizer.pad_token_id,\n",
        "    sampling_mode=\"random\",\n",
        ")\n",
        "\n",
        "print(\"Generated text:\", generated_text)\n",
        "print(\"\\n\")\n",
        "\n",
        "visualizations.plot_next_token(probs[0], prompt=prompt, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHrgLwtmoY2w"
      },
      "source": [
        "## Summary\n",
        "\n",
        "This is the end of the **Train your own small language model** lab.\n",
        "\n",
        "In this lab, you trained your first SLM and engaged in the following steps.\n",
        "\n",
        "- **Tokenized the dataset:** You used the `SimpleWordTokenizer` from the previous lab to tokenize and convert the paragraphs in the dataset to token IDs.\n",
        "\n",
        "- **Padded the paragraphs:** You ensured all paragraphs had the same length by truncating some of them and padding others with a special `\"<PAD>\"` token. This is crucial for processing data in neural networks, such as transformer language models.\n",
        "\n",
        "- **Prepared the input and target data:** You created input-target pairs, where the target is the input sequence shifted by one token. This teaches the model to predict the next token based on the context of previous tokens.\n",
        "\n",
        "- **Shuffled and batched the data:** You shuffled the dataset to increase the diversity of the data within each batch and grouped the paragraphs into batches for training.\n",
        "\n",
        "- **Trained the SLM:** You defined and trained a small transformer model, observing how the training loss decreased during training.\n",
        "\n",
        "- **Prompted the trained model:** You experimented with prompting the model, observing its ability to predict the likely next word, generate coherent text, and adapt to changes in context.\n",
        "\n",
        "As you performed your evaluations, you may have noticed that some of the model predictions are not as good as the ones that you have seen with the Gemma model. This is expected since your model is a lot smaller than the Gemma model. It has been trained on *a lot* less text data. Nevertheless, your model should be able to produce grammatical sentences, even if they do not always make a lot of sense.\n",
        "\n",
        "In the next section of the course, you will explore model evaluation in a little more depth. You will then move on to think about the kinds of problems you are interested in using language models to address."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Solutions\n",
        "\n",
        "The following cells provide reference solutions to the coding activities above. If you really get stuck after trying to solve the activities yourself, you may want to consult these solutions.\n",
        "\n",
        "However, we recommend that you *only* look at the solutions after you have tried to solve the activities above *multiple times*. The best way to learn challenging concepts in computer science and artifical intelligence is to debug your code piece by piece until it works rather than copying existing solutions.\n",
        "\n",
        "If you feel stuck, you may want to first try to debug your code, for example, by adding additional print statements to see what your code is doing at every step. This will provide you with a much deeper understanding of the code and the materials. It will also make you practice how to solve challenging coding problems beyond this course.\n",
        "\n",
        "To view the solutions for an activity, click on the arrow to the left of the activity name. If you consult the solutions, do not copy and paste them into the cells above. Instead, look at them and then type them manually into the cell. This will help you understand where you went wrong."
      ],
      "metadata": {
        "id": "TbCry1ll6L9g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Coding Activity 1"
      ],
      "metadata": {
        "id": "4NJgcGxO6UDE"
      }
    },
    {
      "metadata": {
        "id": "UD38Eu8K7sXg"
      },
      "cell_type": "code",
      "source": [
        "# Add this code in the cell for Activity 1 above.\n",
        "longest_paragraph_length = len(max(encoded_tokens, key=len))\n",
        "shortest_paragraph_length = len(min(encoded_tokens, key=len))\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "collapsed_sections": [
        "NDWsJUGcf4Ru",
        "TbCry1ll6L9g",
        "4NJgcGxO6UDE"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}